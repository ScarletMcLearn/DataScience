{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/scarlet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opening files from directory converting em to string cuz ggezlyfzcrzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/home/scarlet/Projects/Data Science/Data/Short Stories/“Alma” - Junot Díaz.txt', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = file.read()\n",
    "\n",
    "# print (fl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\r\\nJAIME HERNANDEZ\\r\\nYou have a girlfriend named Alma, who has a long tender horse neck and a big Dominican ass that seems to exist in a fourth dimension beyond jeans. An ass that could drag the moon out of orbit. An ass she never liked until she met you. Ain\\x92t a day that passes that you don\\x92t want to press your face against that ass or bite the delicate sliding tendons of her neck. You love how she shivers when you bite, how she fights you with those arms that are so skinny they belong on an after-school special.\\r\\n\\r\\nAlma is a Mason Gross student, one of those Sonic Youth, comic-book-reading alternatinas without whom you might never have lost your virginity. Grew up in Hoboken, part of the Latino community that got its heart burned out in the eighties, tenements turning to flame. Spent nearly every teen-age day on the Lower East Side, thought it would always be home, but then N.Y.U. and Columbia both said nyet, and she ended up even farther from the city than before. She is in a painting phase, and the people she paints are all the color of mold, look like they\\x92ve just been dredged from the bottom of a lake. Her last painting was of you, slouching against the front door: only your frowning I-had-a-lousy-Third-World-childhood-and-all-I-got-was-this-attitude eyes recognizable. She did give you one huge forearm. I told you I\\x92d get the muscles in. The past couple of weeks, now that the warm is here, Alma has abandoned black, started wearing these nothing dresses made out of what feels like tissue paper; it wouldn\\x92t take more than a strong wind to undress her. She says she does it for you: I\\x92m reclaiming my Dominican heritage (which ain\\x92t a complete lie\\x97she\\x92s even taking Spanish to better minister to your mom), and when you see her on the street, flaunting, flaunting, you know exactly what every nigger that walks by is thinking. You met at the weekly Latin parties at the DownUnder in New Brunswick. She never went to those parties, was dragged there by her high-school best friend, Patricia, who still listened to TKA, and this was how you got the chance to strike while, as your boys put it, the pussy was hot.\\r\\n\\r\\nAlma is slender as a reed, you a steroid-addicted block; Alma loves driving, you books; Alma owns a Saturn (bought for her by her carpenter father, who speaks only English in the house), you have no points on your license; Alma\\x92s nails are too dirty for cooking, your spaghetti con pollo is the best in the land. You are so very different\\x97she rolls her eyes every time you turn on the news and says she can\\x92t \\x93stand\\x94 politics. She won\\x92t even call herself Hispanic. She brags to her girls that you\\x92re a \\x93radical\\x94 and a real Dominican (even though on the Pl\\xe1tano Index you wouldn\\x92t rank, Alma being only the third Latina you\\x92ve ever really dated). You brag to your boys that she has more albums than any of them do, that she says terrible white-girl things while you fuck. She\\x92s more adventurous in bed than any girl you\\x92ve had; on your first date she asked you if you wanted to come on her tits or her face, and maybe during boy training you didn\\x92t get one of the memos but you were, like, umm, neither. And at least once a week she will kneel on the mattress before you and, with one hand pulling at her dark nipples, will play with herself, not letting you touch at all, fingers whisking the soft of her and her face looking desperately, furiously happy. She loves to talk while she\\x92s being dirty, too, will whisper, You like watching me don\\x92t you, you like listening to me come, and when she finishes lets out this long demolished groan and only then will she allow you to pull her into an embrace as she wipes her gummy fingers on your chest. This is me, she says.\\r\\n\\r\\nYes\\x97it\\x92s an opposites-attract sort of thing, it\\x92s a great-sex sort of thing, it\\x92s a no-thinking sort of thing. It\\x92s wonderful! Wonderful! Until one June day Alma discovers that you are also fucking this beautiful freshman girl named Laxmi, discovers the fucking of Laxmi because she, Alma, the girlfriend, opens your journal and reads. (Oh, she had her suspicions.) She waits for you on the stoop, and when you pull up in her Saturn and notice the journal in her hand your heart plunges through you like a fat bandit through a hangman\\x92s trap. You take your time turning off the car. You are overwhelmed by a pelagic sadness. Sadness at being caught, at the incontrovertible knowledge that she will never forgive you. You stare at her incredible legs and between them, to that even more incredible p\\xf3pola you\\x92ve loved so inconstantly these past eight months. Only when she starts walking over in anger do you finally step out. You dance across the lawn, powered by the last fumes of your outrageous sinverg\\xfcenzer\\xeda. Hey, mu\\xf1eca, you say, prevaricating to the end. When she starts shrieking, you ask her, Darling, what ever is the matter? She calls you:\\r\\n\\r\\na cocksucker\\r\\n\\r\\na punk motherfucker\\r\\n\\r\\na fake-ass Dominican.\\r\\n\\r\\nShe claims:\\r\\n\\r\\nyou have a little penis\\r\\n\\r\\nno penis\\r\\n\\r\\nand worst of all that you like curried pussy.\\r\\n\\r\\n(Which really is unfair, you try to say, since Laxmi is technically from Guyana, but Alma isn\\x92t listening.)\\r\\n\\r\\nInstead of lowering your head and copping to it like a man, you pick up the journal as one might hold a baby\\x92s beshatted diaper, as one might pinch a recently be-nutted condom. You glance at the offending passages. Then you look at her and smile a smile your dissembling face will remember until the day you die. Baby, you say, baby, this is part of my novel.\\r\\n\\r\\nThis is how you lose her. ?'\n"
     ]
    }
   ],
   "source": [
    "print(str(fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to list all files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '/home/scarlet/Projects/Data Science/Data/Short Stories/'\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“The Faery Handbag” - Kelly Link.txt',\n",
       " '“Symbols and Signs” - Vladimir Nabokov.txt',\n",
       " '“Alma” - Junot Díaz.txt',\n",
       " '“The Ones Who Walk Away from Omelas” - Ursula K. Le Guin.txt',\n",
       " '“The Water That Falls on You from Nowhere” - John Chu.txt',\n",
       " '“Broads” - Roxane Gay.txt',\n",
       " '“The Cartographer Wasps and the Anarchist Bees” - E. Lily Yu.txt',\n",
       " '“The Dead” - James Joyce.txt',\n",
       " \"The Hunter's Wife - ANTHONY DOERR.txt\",\n",
       " 'Premium Harmony - STEVEN KING.txt',\n",
       " '“The Veldt” - Ray Bradbury.txt',\n",
       " 'YOUNGER WOMEN - KAREN JOY FOWLER.txt',\n",
       " '“The Cask of Amontillado” - Edgar Allan Poe.txt',\n",
       " '“Bartleby, the Scrivener” - Herman Melville.txt',\n",
       " 'Ghosts and Empties - Lauren Groff.txt',\n",
       " \"The Monkey's Paw - W. W. Jacobs.txt\",\n",
       " '“The Celebrated Jumping Frog of Calaveras County” - Mark Twain.txt']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43039\n",
      "12660\n",
      "5535\n",
      "12996\n",
      "34851\n",
      "18579\n",
      "19623\n",
      "86787\n",
      "52311\n",
      "20059\n",
      "28087\n",
      "15812\n",
      "13153\n",
      "83510\n",
      "20532\n",
      "22012\n",
      "13594\n"
     ]
    }
   ],
   "source": [
    "for itm in onlyfiles:\n",
    "    file = open('/home/scarlet/Projects/Data Science/Data/Short Stories/' + itm, 'rb')\n",
    "    print(len(file.read()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "\n",
    "for itm in onlyfiles:\n",
    "    file = open('/home/scarlet/Projects/Data Science/Data/Short Stories/' + itm, 'rb')\n",
    "#     print(len(file.read()))\n",
    "    \n",
    "    docs.append(str((file.read())))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "postDocs = [x.lower() for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "stopset.update(['lt','p','/p','br','amp','quot','field','font','normal','span','0px','rgb','style','51', \n",
    "                'spacing','text','helvetica','size','family', 'space', 'arial', 'height', 'indent', 'letter'\n",
    "                'line','none','sans','serif','transform','line','variant','weight','times', 'new','strong', 'video', 'title'\n",
    "                'white','word','letter', 'roman','0pt','16','color','12','14','21', 'neue', 'apple', 'class',  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(postDocs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopset,\n",
    "                                 use_idf=True, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(postDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x99464 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9257 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 87792)\t0.03505637772900067\n",
      "  (0, 31355)\t0.03423311207867166\n",
      "  (0, 83357)\t0.004706052559206268\n",
      "  (0, 78797)\t0.0036857967141512805\n",
      "  (0, 28987)\t0.015993245214577755\n",
      "  (0, 93951)\t0.0744142915330905\n",
      "  (0, 80763)\t0.00622420219612212\n",
      "  (0, 85057)\t0.003357347693655032\n",
      "  (0, 8864)\t0.009412105118412535\n",
      "  (0, 29942)\t0.02054620574353763\n",
      "  (0, 19866)\t0.016436964594830104\n",
      "  (0, 37464)\t0.0046741836972000895\n",
      "  (0, 88397)\t0.004706052559206268\n",
      "  (0, 13797)\t0.016436964594830104\n",
      "  (0, 89563)\t0.0036857967141512805\n",
      "  (0, 23622)\t0.017574424598228132\n",
      "  (0, 4097)\t0.0036857967141512805\n",
      "  (0, 75807)\t0.0030889853036525387\n",
      "  (0, 47510)\t0.004393606149557033\n",
      "  (0, 13776)\t0.008586264407664287\n",
      "  (0, 6511)\t0.00975456576277088\n",
      "  (0, 94440)\t0.17794104905705985\n",
      "  (0, 41248)\t0.013180818448671099\n",
      "  (0, 44357)\t0.04710137753916189\n",
      "  (0, 90755)\t0.044203974979994606\n",
      "  :\t:\n",
      "  (0, 68719)\t0.004706052559206268\n",
      "  (0, 93508)\t0.004706052559206268\n",
      "  (0, 72955)\t0.004706052559206268\n",
      "  (0, 65685)\t0.004706052559206268\n",
      "  (0, 76388)\t0.004706052559206268\n",
      "  (0, 94019)\t0.004706052559206268\n",
      "  (0, 50199)\t0.004706052559206268\n",
      "  (0, 99450)\t0.004706052559206268\n",
      "  (0, 94707)\t0.004706052559206268\n",
      "  (0, 29431)\t0.004706052559206268\n",
      "  (0, 83970)\t0.004706052559206268\n",
      "  (0, 93215)\t0.004706052559206268\n",
      "  (0, 9268)\t0.004706052559206268\n",
      "  (0, 22692)\t0.004706052559206268\n",
      "  (0, 81571)\t0.004706052559206268\n",
      "  (0, 51138)\t0.004706052559206268\n",
      "  (0, 91374)\t0.004706052559206268\n",
      "  (0, 78870)\t0.004706052559206268\n",
      "  (0, 93568)\t0.004706052559206268\n",
      "  (0, 81531)\t0.004706052559206268\n",
      "  (0, 25510)\t0.004706052559206268\n",
      "  (0, 93200)\t0.004706052559206268\n",
      "  (0, 7122)\t0.004706052559206268\n",
      "  (0, 7157)\t0.004706052559206268\n",
      "  (0, 78857)\t0.004706052559206268\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 99464)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=27, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components=27, n_iter=100)\n",
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00154377, 0.00092266, 0.00092266, ..., 0.00114066, 0.00114066,\n",
       "       0.00114066])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 (default, Nov 23 2017, 16:37:01) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "x94\n",
      "x92s\n",
      "x92t\n",
      "said\n",
      "zofia\n",
      "gus\n",
      "jude\n",
      "x93i\n",
      "bartleby\n",
      "like\n",
      " \n",
      "Concept 1:\n",
      "said\n",
      "gabriel\n",
      "hunter\n",
      "old\n",
      "aunt\n",
      "george\n",
      "nursery\n",
      "kate\n",
      "nthe\n",
      "lions\n",
      " \n",
      "Concept 2:\n",
      "alma\n",
      "jimmy\n",
      "greta\n",
      "x92s\n",
      "smiley\n",
      "omelas\n",
      "x92t\n",
      "walk\n",
      "frog\n",
      "ass\n",
      " \n",
      "Concept 3:\n",
      "wasps\n",
      "hive\n",
      "wasp\n",
      "bees\n",
      "queen\n",
      "foundress\n",
      "paper\n",
      "nest\n",
      "maps\n",
      "anarchists\n",
      " \n",
      "Concept 4:\n",
      "smiley\n",
      "frog\n",
      "feller\n",
      "bet\n",
      "dan\n",
      "leonidas\n",
      "leonidas smiley\n",
      "wheeler\n",
      "would\n",
      "omelas\n",
      " \n",
      "Concept 5:\n",
      "amontillado\n",
      "ugh\n",
      "fortunato\n",
      "ugh ugh\n",
      "ugh ugh ugh\n",
      "wasps\n",
      "hive\n",
      "jimmy\n",
      "greta\n",
      "wasp\n",
      " \n",
      "Concept 6:\n",
      "omelas\n",
      "child\n",
      "amontillado\n",
      "ugh\n",
      "fortunato\n",
      "ugh ugh\n",
      "ugh ugh ugh\n",
      "upon\n",
      "happiness\n",
      "festival\n",
      " \n",
      "Concept 7:\n",
      "jimmy\n",
      "greta\n",
      "nolan\n",
      "greta x92s\n",
      "jimmy x92s\n",
      "njimmy\n",
      "jimmy nolan\n",
      "broads\n",
      "ngreta\n",
      "hands\n",
      " \n",
      "Concept 8:\n",
      "jimmy\n",
      "greta\n",
      "alma\n",
      "gabriel\n",
      "aunt\n",
      "nolan\n",
      "husband\n",
      "greta x92s\n",
      "hands\n",
      "ass\n",
      " \n",
      "Concept 9:\n",
      "walk\n",
      "neighborhood\n",
      "nuns\n",
      "swans\n",
      "night\n",
      "homeless\n",
      "house\n",
      "pond\n",
      "amontillado\n",
      "houses\n",
      " \n",
      "Concept 10:\n",
      "george\n",
      "nursery\n",
      "lions\n",
      "jimmy\n",
      "greta\n",
      "hadley\n",
      "george hadley\n",
      "peter\n",
      "africa\n",
      "lydia\n",
      " \n",
      "Concept 11:\n",
      "gabriel\n",
      "aunt\n",
      "kate\n",
      "aunt kate\n",
      "miss\n",
      "julia\n",
      "mary jane\n",
      "browne\n",
      "jane\n",
      "mr browne\n",
      " \n",
      "Concept 12:\n",
      "hunter\n",
      "snow\n",
      "truck\n",
      "cabin\n",
      "river\n",
      "wolves\n",
      "maples\n",
      "nthe hunter\n",
      "winter\n",
      "gabriel\n",
      " \n",
      "Concept 13:\n",
      "bartleby\n",
      "turkey\n",
      "nippers\n",
      "x94 said\n",
      "upon\n",
      "x94\n",
      "prefer\n",
      "office\n",
      "would prefer\n",
      "scrivener\n",
      " \n",
      "Concept 14:\n",
      "zofia\n",
      "handbag\n",
      "jake\n",
      "zofia said\n",
      "x94 zofia\n",
      "hill\n",
      "x94 zofia said\n",
      "zofia x92s\n",
      "x94 said\n",
      "scrabble\n",
      " \n",
      "Concept 15:\n",
      "gus\n",
      "ray\n",
      "x92s\n",
      "x92ll\n",
      "x92m\n",
      "ghosh\n",
      "sister\n",
      "mom\n",
      "mary\n",
      "mr ghosh\n",
      " \n",
      "Concept 16:\n",
      "ray\n",
      "ghosh\n",
      "says\n",
      "x94 says\n",
      "mary\n",
      "mr ghosh\n",
      "biz\n",
      "x94\n",
      "zofia\n",
      "x94 ray\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_): \n",
    "    termsInComp = zip (terms,comp)\n",
    "    sortedTerms =  sorted(termsInComp, key=lambda x: x[1], reverse=True) [:10]\n",
    "    print(\"Concept %d:\" % i )\n",
    "    for term in sortedTerms:\n",
    "        print(term[0])\n",
    "    print (\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00154377,  0.00092266,  0.00092266, ...,  0.00114066,\n",
       "         0.00114066,  0.00114066],\n",
       "       [-0.00049844, -0.00054973, -0.00054973, ..., -0.00039736,\n",
       "        -0.00039736, -0.00039736],\n",
       "       [ 0.00057254,  0.00169627,  0.00169627, ..., -0.00035441,\n",
       "        -0.00035441, -0.00035441],\n",
       "       ...,\n",
       "       [ 0.00048684,  0.00066931,  0.00066931, ...,  0.00424437,\n",
       "         0.00424437,  0.00424437],\n",
       "       [-0.00087735, -0.00075964, -0.00075964, ..., -0.00222927,\n",
       "        -0.00222927, -0.00222927],\n",
       "       [-0.00065136, -0.0001929 , -0.0001929 , ...,  0.00068938,\n",
       "         0.00068938,  0.00068938]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "docA = \"the cat sat on my face\"\n",
    "docB = \"the dog sat on my bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowA = docA.split(\" \")   #bow = bag of words\n",
    "bowB = docB.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'dog', 'sat', 'on', 'my', 'bed'] "
     ]
    }
   ],
   "source": [
    "print(bowB, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSet= set(bowA).union(set(bowB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bed', 'cat', 'dog', 'face', 'my', 'on', 'sat', 'the'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(wordSet, 0)\n",
    "wordDictB = dict.fromkeys(wordSet, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bowA:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "for word in bowB:\n",
    "    wordDictB[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bed': 0, 'cat': 1, 'dog': 0, 'face': 1, 'my': 1, 'on': 1, 'sat': 1, 'the': 1}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bed</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>face</th>\n",
       "      <th>my</th>\n",
       "      <th>on</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bed  cat  dog  face  my  on  sat  the\n",
       "0    0    1    0     1   1   1    1    1\n",
       "1    1    0    1     0   1   1    1    1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfBowA = computeTF(wordDictA, bowA)\n",
    "tfBowB = computeTF(wordDictB, bowB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    #counts the number of documents that contain a word w\n",
    "    idfDict = dict.fromkeys(docList[0].keys(),0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] +=1\n",
    "                \n",
    "    #divide N by denominator above, take the log of that\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word]= math.log(N / float(val)) \n",
    "\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA =  computeTFIDF(tfBowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfBowB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bed</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>face</th>\n",
       "      <th>my</th>\n",
       "      <th>on</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bed       cat       dog      face   my   on  sat  the\n",
       "0  0.000000  0.115525  0.000000  0.115525  0.0  0.0  0.0  0.0\n",
       "1  0.115525  0.000000  0.115525  0.000000  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([tfidfBowA, tfidfBowB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
