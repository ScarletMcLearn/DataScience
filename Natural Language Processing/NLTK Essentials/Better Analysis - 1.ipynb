{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/scarlet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opening files from directory converting em to string cuz ggezlyfzcrzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/home/scarlet/Projects/Data Science/Data/Short Stories/“Alma” - Junot Díaz.txt', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = file.read()\n",
    "\n",
    "# print (fl )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\r\\nJAIME HERNANDEZ\\r\\nYou have a girlfriend named Alma, who has a long tender horse neck and a big Dominican ass that seems to exist in a fourth dimension beyond jeans. An ass that could drag the moon out of orbit. An ass she never liked until she met you. Ain\\x92t a day that passes that you don\\x92t want to press your face against that ass or bite the delicate sliding tendons of her neck. You love how she shivers when you bite, how she fights you with those arms that are so skinny they belong on an after-school special.\\r\\n\\r\\nAlma is a Mason Gross student, one of those Sonic Youth, comic-book-reading alternatinas without whom you might never have lost your virginity. Grew up in Hoboken, part of the Latino community that got its heart burned out in the eighties, tenements turning to flame. Spent nearly every teen-age day on the Lower East Side, thought it would always be home, but then N.Y.U. and Columbia both said nyet, and she ended up even farther from the city than before. She is in a painting phase, and the people she paints are all the color of mold, look like they\\x92ve just been dredged from the bottom of a lake. Her last painting was of you, slouching against the front door: only your frowning I-had-a-lousy-Third-World-childhood-and-all-I-got-was-this-attitude eyes recognizable. She did give you one huge forearm. I told you I\\x92d get the muscles in. The past couple of weeks, now that the warm is here, Alma has abandoned black, started wearing these nothing dresses made out of what feels like tissue paper; it wouldn\\x92t take more than a strong wind to undress her. She says she does it for you: I\\x92m reclaiming my Dominican heritage (which ain\\x92t a complete lie\\x97she\\x92s even taking Spanish to better minister to your mom), and when you see her on the street, flaunting, flaunting, you know exactly what every nigger that walks by is thinking. You met at the weekly Latin parties at the DownUnder in New Brunswick. She never went to those parties, was dragged there by her high-school best friend, Patricia, who still listened to TKA, and this was how you got the chance to strike while, as your boys put it, the pussy was hot.\\r\\n\\r\\nAlma is slender as a reed, you a steroid-addicted block; Alma loves driving, you books; Alma owns a Saturn (bought for her by her carpenter father, who speaks only English in the house), you have no points on your license; Alma\\x92s nails are too dirty for cooking, your spaghetti con pollo is the best in the land. You are so very different\\x97she rolls her eyes every time you turn on the news and says she can\\x92t \\x93stand\\x94 politics. She won\\x92t even call herself Hispanic. She brags to her girls that you\\x92re a \\x93radical\\x94 and a real Dominican (even though on the Pl\\xe1tano Index you wouldn\\x92t rank, Alma being only the third Latina you\\x92ve ever really dated). You brag to your boys that she has more albums than any of them do, that she says terrible white-girl things while you fuck. She\\x92s more adventurous in bed than any girl you\\x92ve had; on your first date she asked you if you wanted to come on her tits or her face, and maybe during boy training you didn\\x92t get one of the memos but you were, like, umm, neither. And at least once a week she will kneel on the mattress before you and, with one hand pulling at her dark nipples, will play with herself, not letting you touch at all, fingers whisking the soft of her and her face looking desperately, furiously happy. She loves to talk while she\\x92s being dirty, too, will whisper, You like watching me don\\x92t you, you like listening to me come, and when she finishes lets out this long demolished groan and only then will she allow you to pull her into an embrace as she wipes her gummy fingers on your chest. This is me, she says.\\r\\n\\r\\nYes\\x97it\\x92s an opposites-attract sort of thing, it\\x92s a great-sex sort of thing, it\\x92s a no-thinking sort of thing. It\\x92s wonderful! Wonderful! Until one June day Alma discovers that you are also fucking this beautiful freshman girl named Laxmi, discovers the fucking of Laxmi because she, Alma, the girlfriend, opens your journal and reads. (Oh, she had her suspicions.) She waits for you on the stoop, and when you pull up in her Saturn and notice the journal in her hand your heart plunges through you like a fat bandit through a hangman\\x92s trap. You take your time turning off the car. You are overwhelmed by a pelagic sadness. Sadness at being caught, at the incontrovertible knowledge that she will never forgive you. You stare at her incredible legs and between them, to that even more incredible p\\xf3pola you\\x92ve loved so inconstantly these past eight months. Only when she starts walking over in anger do you finally step out. You dance across the lawn, powered by the last fumes of your outrageous sinverg\\xfcenzer\\xeda. Hey, mu\\xf1eca, you say, prevaricating to the end. When she starts shrieking, you ask her, Darling, what ever is the matter? She calls you:\\r\\n\\r\\na cocksucker\\r\\n\\r\\na punk motherfucker\\r\\n\\r\\na fake-ass Dominican.\\r\\n\\r\\nShe claims:\\r\\n\\r\\nyou have a little penis\\r\\n\\r\\nno penis\\r\\n\\r\\nand worst of all that you like curried pussy.\\r\\n\\r\\n(Which really is unfair, you try to say, since Laxmi is technically from Guyana, but Alma isn\\x92t listening.)\\r\\n\\r\\nInstead of lowering your head and copping to it like a man, you pick up the journal as one might hold a baby\\x92s beshatted diaper, as one might pinch a recently be-nutted condom. You glance at the offending passages. Then you look at her and smile a smile your dissembling face will remember until the day you die. Baby, you say, baby, this is part of my novel.\\r\\n\\r\\nThis is how you lose her. ?'\n"
     ]
    }
   ],
   "source": [
    "print(str(fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to list all files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '/home/scarlet/Projects/Data Science/Data/Short Stories/'\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“The Faery Handbag” - Kelly Link.txt',\n",
       " '“Symbols and Signs” - Vladimir Nabokov.txt',\n",
       " '“Alma” - Junot Díaz.txt',\n",
       " '“The Ones Who Walk Away from Omelas” - Ursula K. Le Guin.txt',\n",
       " '“The Water That Falls on You from Nowhere” - John Chu.txt',\n",
       " '“Broads” - Roxane Gay.txt',\n",
       " '“The Cartographer Wasps and the Anarchist Bees” - E. Lily Yu.txt',\n",
       " '“The Dead” - James Joyce.txt',\n",
       " \"The Hunter's Wife - ANTHONY DOERR.txt\",\n",
       " 'Premium Harmony - STEVEN KING.txt',\n",
       " '“The Veldt” - Ray Bradbury.txt',\n",
       " 'YOUNGER WOMEN - KAREN JOY FOWLER.txt',\n",
       " '“The Cask of Amontillado” - Edgar Allan Poe.txt',\n",
       " '“Bartleby, the Scrivener” - Herman Melville.txt',\n",
       " 'Ghosts and Empties - Lauren Groff.txt',\n",
       " \"The Monkey's Paw - W. W. Jacobs.txt\",\n",
       " '“The Celebrated Jumping Frog of Calaveras County” - Mark Twain.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43039\n",
      "12660\n",
      "5535\n",
      "12996\n",
      "34851\n",
      "18579\n",
      "19623\n",
      "86787\n",
      "52311\n",
      "20059\n",
      "28087\n",
      "15812\n",
      "13153\n",
      "83510\n",
      "20532\n",
      "22012\n",
      "13594\n"
     ]
    }
   ],
   "source": [
    "for itm in onlyfiles:\n",
    "    file = open('/home/scarlet/Projects/Data Science/Data/Short Stories/' + itm, 'rb')\n",
    "    print(len(file.read()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "\n",
    "for itm in onlyfiles:\n",
    "    file = open('/home/scarlet/Projects/Data Science/Data/Short Stories/' + itm, 'rb')\n",
    "#     print(len(file.read()))\n",
    "    \n",
    "    docs.append(str((file.read())))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "postDocs = [x.lower() for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "stopset.update(['lt','p','/p','br','amp','quot','field','font','normal','span','0px','rgb','style','51', \n",
    "                'spacing','text','helvetica','size','family', 'space', 'arial', 'height', 'indent', 'letter'\n",
    "                'line','none','sans','serif','transform','line','variant','weight','times', 'new','strong', 'video', 'title'\n",
    "                'white','word','letter', 'roman','0pt','16','color','12','14','21', 'neue', 'apple', 'class',  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(postDocs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvectorizer = TfidfVectorizer(stop_words=stopset,\n",
    "                                 use_idf=True, ngram_range=(1, 3), )\n",
    "X = vectorizer.fit_transform(postDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x99464 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9257 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 87792)\t0.03505637772900067\n",
      "  (0, 31355)\t0.03423311207867166\n",
      "  (0, 83357)\t0.004706052559206268\n",
      "  (0, 78797)\t0.0036857967141512805\n",
      "  (0, 28987)\t0.015993245214577755\n",
      "  (0, 93951)\t0.0744142915330905\n",
      "  (0, 80763)\t0.00622420219612212\n",
      "  (0, 85057)\t0.003357347693655032\n",
      "  (0, 8864)\t0.009412105118412535\n",
      "  (0, 29942)\t0.02054620574353763\n",
      "  (0, 19866)\t0.016436964594830104\n",
      "  (0, 37464)\t0.0046741836972000895\n",
      "  (0, 88397)\t0.004706052559206268\n",
      "  (0, 13797)\t0.016436964594830104\n",
      "  (0, 89563)\t0.0036857967141512805\n",
      "  (0, 23622)\t0.017574424598228132\n",
      "  (0, 4097)\t0.0036857967141512805\n",
      "  (0, 75807)\t0.0030889853036525387\n",
      "  (0, 47510)\t0.004393606149557033\n",
      "  (0, 13776)\t0.008586264407664287\n",
      "  (0, 6511)\t0.00975456576277088\n",
      "  (0, 94440)\t0.17794104905705985\n",
      "  (0, 41248)\t0.013180818448671099\n",
      "  (0, 44357)\t0.04710137753916189\n",
      "  (0, 90755)\t0.044203974979994606\n",
      "  :\t:\n",
      "  (0, 68719)\t0.004706052559206268\n",
      "  (0, 93508)\t0.004706052559206268\n",
      "  (0, 72955)\t0.004706052559206268\n",
      "  (0, 65685)\t0.004706052559206268\n",
      "  (0, 76388)\t0.004706052559206268\n",
      "  (0, 94019)\t0.004706052559206268\n",
      "  (0, 50199)\t0.004706052559206268\n",
      "  (0, 99450)\t0.004706052559206268\n",
      "  (0, 94707)\t0.004706052559206268\n",
      "  (0, 29431)\t0.004706052559206268\n",
      "  (0, 83970)\t0.004706052559206268\n",
      "  (0, 93215)\t0.004706052559206268\n",
      "  (0, 9268)\t0.004706052559206268\n",
      "  (0, 22692)\t0.004706052559206268\n",
      "  (0, 81571)\t0.004706052559206268\n",
      "  (0, 51138)\t0.004706052559206268\n",
      "  (0, 91374)\t0.004706052559206268\n",
      "  (0, 78870)\t0.004706052559206268\n",
      "  (0, 93568)\t0.004706052559206268\n",
      "  (0, 81531)\t0.004706052559206268\n",
      "  (0, 25510)\t0.004706052559206268\n",
      "  (0, 93200)\t0.004706052559206268\n",
      "  (0, 7122)\t0.004706052559206268\n",
      "  (0, 7157)\t0.004706052559206268\n",
      "  (0, 78857)\t0.004706052559206268\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '10 35',\n",
       " '10 35 evening',\n",
       " '10 nippers',\n",
       " '10 nippers second',\n",
       " '100',\n",
       " '100 x93i',\n",
       " '100 x93i would',\n",
       " '101',\n",
       " '101 x93will',\n",
       " '101 x93will tell',\n",
       " '102',\n",
       " '102 x93i',\n",
       " '102 x93i would',\n",
       " '103',\n",
       " '103 x93but',\n",
       " '103 x93but reasonable',\n",
       " '104',\n",
       " '104 look',\n",
       " '104 look spoke',\n",
       " '105',\n",
       " '105 x93what',\n",
       " '105 x93what answer',\n",
       " '106',\n",
       " '106 x93at',\n",
       " '106 x93at present',\n",
       " '107',\n",
       " '107 rather',\n",
       " '107 rather weak',\n",
       " '108',\n",
       " '108 sat',\n",
       " '108 sat ruminating',\n",
       " '109',\n",
       " '109 x93at',\n",
       " '109 x93at present',\n",
       " '11',\n",
       " '11 though',\n",
       " '11 though concerning',\n",
       " '110',\n",
       " '110 folding',\n",
       " '110 folding doors',\n",
       " '111',\n",
       " '111 x93prefer',\n",
       " '111 x93prefer eh',\n",
       " '112',\n",
       " '112 bartleby',\n",
       " '112 bartleby moved',\n",
       " '113',\n",
       " '113 x93mr',\n",
       " '113 x93mr nippers',\n",
       " '114',\n",
       " '114 somehow',\n",
       " '114 somehow late',\n",
       " '115',\n",
       " '115 nippers',\n",
       " '115 nippers looking',\n",
       " '116',\n",
       " '116 x93with',\n",
       " '116 x93with submission',\n",
       " '117',\n",
       " '117 x93so',\n",
       " '117 x93so got',\n",
       " '118',\n",
       " '118 x93with',\n",
       " '118 x93with submission',\n",
       " '119',\n",
       " '119 x93i',\n",
       " '119 x93i would',\n",
       " '120',\n",
       " '120 x93that',\n",
       " '120 x93that x92s',\n",
       " '121',\n",
       " '121 x93oh',\n",
       " '121 x93oh prefer',\n",
       " '122',\n",
       " '122 x93turkey',\n",
       " '122 x93turkey x94',\n",
       " '123',\n",
       " '123 x93oh',\n",
       " '123 x93oh certainly',\n",
       " '124',\n",
       " '124 opened',\n",
       " '124 opened folding',\n",
       " '125',\n",
       " '125 next',\n",
       " '125 next day',\n",
       " '126',\n",
       " '126 x93why',\n",
       " '126 x93why next',\n",
       " '127',\n",
       " '127 x93no',\n",
       " '127 x93no x94',\n",
       " '128',\n",
       " '128 x93and',\n",
       " '128 x93and reason',\n",
       " '129',\n",
       " '129 x93do',\n",
       " '129 x93do see',\n",
       " '13',\n",
       " '13 ginger',\n",
       " '13 ginger nut',\n",
       " '130',\n",
       " '130 looked',\n",
       " '130 looked steadfastly',\n",
       " '131',\n",
       " '131 touched',\n",
       " '131 touched said',\n",
       " '132',\n",
       " '132 still',\n",
       " '132 still added',\n",
       " '133',\n",
       " '133 x93what',\n",
       " '133 x93what x94',\n",
       " '134',\n",
       " '134 x93i',\n",
       " '134 x93i given',\n",
       " '135',\n",
       " '135 remained',\n",
       " '135 remained ever',\n",
       " '136',\n",
       " '136 expiration',\n",
       " '136 expiration period',\n",
       " '137',\n",
       " '137 buttoned',\n",
       " '137 buttoned coat',\n",
       " '138',\n",
       " '138 x93i',\n",
       " '138 x93i would',\n",
       " '139',\n",
       " '139 x93you',\n",
       " '139 x93you must',\n",
       " '140',\n",
       " '140 remained',\n",
       " '140 remained silent',\n",
       " '141',\n",
       " '141 unbounded',\n",
       " '141 unbounded confidence',\n",
       " '142',\n",
       " '142 x93bartleby',\n",
       " '142 x93bartleby x94',\n",
       " '143',\n",
       " '143 made',\n",
       " '143 made motion',\n",
       " '144',\n",
       " '144 x93i',\n",
       " '144 x93i leave',\n",
       " '145',\n",
       " '145 answered',\n",
       " '145 answered like',\n",
       " '146',\n",
       " '146 walked',\n",
       " '146 walked home',\n",
       " '147',\n",
       " '147 breakfast',\n",
       " '147 breakfast walked',\n",
       " '148',\n",
       " '148 x93i',\n",
       " '148 x93i x92ll',\n",
       " '149',\n",
       " '149 x93doesn',\n",
       " '149 x93doesn x92t',\n",
       " '15',\n",
       " '15 words',\n",
       " '15 words touching',\n",
       " '150',\n",
       " '150 instinctively',\n",
       " '150 instinctively putting',\n",
       " '151',\n",
       " '151 intended',\n",
       " '151 intended earlier',\n",
       " '152',\n",
       " '152 bartleby',\n",
       " '152 bartleby 153',\n",
       " '153',\n",
       " '153 thunderstruck',\n",
       " '153 thunderstruck instant',\n",
       " '154',\n",
       " '154 x93not',\n",
       " '154 x93not gone',\n",
       " '155',\n",
       " '155 x93bartleby',\n",
       " '155 x93bartleby x94',\n",
       " '156',\n",
       " '156 answered',\n",
       " '156 answered nothing',\n",
       " '157',\n",
       " '157 x93will',\n",
       " '157 x93will quit',\n",
       " '158',\n",
       " '158 x93i',\n",
       " '158 x93i would',\n",
       " '159',\n",
       " '159 x93what',\n",
       " '159 x93what earthly',\n",
       " '160',\n",
       " '160 answered',\n",
       " '160 answered nothing',\n",
       " '161',\n",
       " '161 x93are',\n",
       " '161 x93are ready',\n",
       " '162',\n",
       " '162 silently',\n",
       " '162 silently retired',\n",
       " '163',\n",
       " '163 state',\n",
       " '163 state nervous',\n",
       " '164',\n",
       " '164 old',\n",
       " '164 old adam',\n",
       " '165',\n",
       " '165 endeavored',\n",
       " '165 endeavored also',\n",
       " '166',\n",
       " '166 days',\n",
       " '166 days passed',\n",
       " '167',\n",
       " '167 believe',\n",
       " '167 believe wise',\n",
       " '168',\n",
       " '168 also',\n",
       " '168 also reference',\n",
       " '169',\n",
       " '169 ere',\n",
       " '169 ere revolving',\n",
       " '17',\n",
       " '17 first',\n",
       " '17 first bartleby',\n",
       " '170',\n",
       " '170 shall',\n",
       " '170 shall said',\n",
       " '171',\n",
       " '171 something',\n",
       " '171 something severe',\n",
       " '172',\n",
       " '172 acting',\n",
       " '172 acting accordingly',\n",
       " '173',\n",
       " '173 made',\n",
       " '173 made reply',\n",
       " '174',\n",
       " '174 appointed',\n",
       " '174 appointed day',\n",
       " '175',\n",
       " '175 entered',\n",
       " '175 entered hand',\n",
       " '176',\n",
       " '176 x93good',\n",
       " '176 x93good bye',\n",
       " '177',\n",
       " '177 established',\n",
       " '177 established quarters',\n",
       " '178',\n",
       " '178 thought',\n",
       " '178 thought going',\n",
       " '179',\n",
       " '179 full',\n",
       " '179 full forebodings',\n",
       " '18',\n",
       " '18 course',\n",
       " '18 course indispensable',\n",
       " '180',\n",
       " '180 x93then',\n",
       " '180 x93then sir',\n",
       " '181',\n",
       " '181 x93i',\n",
       " '181 x93i sorry',\n",
       " '182',\n",
       " '182 x93in',\n",
       " '182 x93in mercy',\n",
       " '183',\n",
       " '183 x93i',\n",
       " '183 x93i certainly',\n",
       " '184',\n",
       " '184 x93i',\n",
       " '184 x93i shall',\n",
       " '185',\n",
       " '185 several',\n",
       " '185 several days',\n",
       " '186',\n",
       " '186 time',\n",
       " '186 time thought',\n",
       " '187',\n",
       " '187 x93that',\n",
       " '187 x93that x92s',\n",
       " '188',\n",
       " '188 x93you',\n",
       " '188 x93you must',\n",
       " '189',\n",
       " '189 aghast',\n",
       " '189 aghast torrent',\n",
       " '19',\n",
       " '19 haste',\n",
       " '19 haste business',\n",
       " '190',\n",
       " '190 going',\n",
       " '190 going stairs',\n",
       " '191',\n",
       " '191 x93what',\n",
       " '191 x93what bartleby',\n",
       " '192',\n",
       " '192 x93sitting',\n",
       " '192 x93sitting upon',\n",
       " '193',\n",
       " '193 motioned',\n",
       " '193 motioned lawyer',\n",
       " '194',\n",
       " '194 x93bartleby',\n",
       " '194 x93bartleby x94',\n",
       " '195',\n",
       " '195 answer',\n",
       " '195 answer 196',\n",
       " '196',\n",
       " '196 x93now',\n",
       " '196 x93now one',\n",
       " '197',\n",
       " '197 x93no',\n",
       " '197 x93no would',\n",
       " '1972',\n",
       " '1972 winter',\n",
       " '1972 winter arrived',\n",
       " '198',\n",
       " '198 x93would',\n",
       " '198 x93would like',\n",
       " '199',\n",
       " '199 x93there',\n",
       " '199 x93there much',\n",
       " '20',\n",
       " '20 attitude',\n",
       " '20 attitude sit',\n",
       " '200',\n",
       " '200 x93too',\n",
       " '200 x93too much',\n",
       " '2001',\n",
       " '2001 pen',\n",
       " '2001 pen faulkner',\n",
       " '201',\n",
       " '201 x93i',\n",
       " '201 x93i would',\n",
       " '202',\n",
       " '202 x93how',\n",
       " '202 x93how would',\n",
       " '203',\n",
       " '203 x93i',\n",
       " '203 x93i would',\n",
       " '204',\n",
       " '204 unwonted',\n",
       " '204 unwonted wordiness',\n",
       " '205',\n",
       " '205 x93well',\n",
       " '205 x93well would',\n",
       " '206',\n",
       " '206 x93no',\n",
       " '206 x93no would',\n",
       " '207',\n",
       " '207 x93how',\n",
       " '207 x93how would',\n",
       " '208',\n",
       " '208 x93not',\n",
       " '208 x93not strike',\n",
       " '209',\n",
       " '209 x93stationary',\n",
       " '209 x93stationary shall',\n",
       " '210',\n",
       " '210 x93bartleby',\n",
       " '210 x93bartleby x94',\n",
       " '211',\n",
       " '211 x93no',\n",
       " '211 x93no present',\n",
       " '212',\n",
       " '212 answered',\n",
       " '212 answered nothing',\n",
       " '213',\n",
       " '213 entered',\n",
       " '213 entered office',\n",
       " '214',\n",
       " '214 afterwards',\n",
       " '214 afterwards learned',\n",
       " '215',\n",
       " '215 compassionate',\n",
       " '215 compassionate curious',\n",
       " '216',\n",
       " '216 day',\n",
       " '216 day received',\n",
       " '217',\n",
       " '217 disgraceful',\n",
       " '217 disgraceful charge',\n",
       " '218',\n",
       " '218 x93bartleby',\n",
       " '218 x93bartleby x94',\n",
       " '219',\n",
       " '219 x93i',\n",
       " '219 x93i know',\n",
       " '22',\n",
       " '22 x93prefer',\n",
       " '22 x93prefer x94',\n",
       " '220',\n",
       " '220 x93it',\n",
       " '220 x93it brought',\n",
       " '221',\n",
       " '221 x93i',\n",
       " '221 x93i know',\n",
       " '222',\n",
       " '222 entered',\n",
       " '222 entered corridor',\n",
       " '223',\n",
       " '223 x93yes',\n",
       " '223 x93yes x94',\n",
       " '224',\n",
       " '224 x93does',\n",
       " '224 x93does want',\n",
       " '225',\n",
       " '225 x93who',\n",
       " '225 x93who x94',\n",
       " '226',\n",
       " '226 x93i',\n",
       " '226 x93i grub',\n",
       " '227',\n",
       " '227 x93is',\n",
       " '227 x93is x94',\n",
       " '228',\n",
       " '228 said',\n",
       " '228 said 229',\n",
       " '229',\n",
       " '229 x93well',\n",
       " '229 x93well x94',\n",
       " '23',\n",
       " '23 x93i',\n",
       " '23 x93i would',\n",
       " '230',\n",
       " '230 x93introduce',\n",
       " '230 x93introduce x94',\n",
       " '231',\n",
       " '231 thinking',\n",
       " '231 thinking would',\n",
       " '232',\n",
       " '232 x93bartleby',\n",
       " '232 x93bartleby mr',\n",
       " '233',\n",
       " '233 x93your',\n",
       " '233 x93your sarvant',\n",
       " '234',\n",
       " '234 x93i',\n",
       " '234 x93i prefer',\n",
       " '235',\n",
       " '235 x93how',\n",
       " '235 x93how x92s',\n",
       " '236',\n",
       " '236 x93i',\n",
       " '236 x93i think',\n",
       " '237',\n",
       " '237 x93deranged',\n",
       " '237 x93deranged deranged',\n",
       " '238',\n",
       " '238 x93no',\n",
       " '238 x93no never',\n",
       " '239',\n",
       " '239 days',\n",
       " '239 days obtained',\n",
       " '24',\n",
       " '24 looked',\n",
       " '24 looked steadfastly',\n",
       " '240',\n",
       " '240 x93i',\n",
       " '240 x93i saw',\n",
       " '241',\n",
       " '241 went',\n",
       " '241 went direction',\n",
       " '242',\n",
       " '242 x93are',\n",
       " '242 x93are looking',\n",
       " '243',\n",
       " '243 yard',\n",
       " '243 yard entirely',\n",
       " '244',\n",
       " '244 strangely',\n",
       " '244 strangely huddled',\n",
       " '245',\n",
       " '245 round',\n",
       " '245 round face',\n",
       " '246',\n",
       " '246 x93lives',\n",
       " '246 x93lives without',\n",
       " '247',\n",
       " '247 x93eh',\n",
       " '247 x93eh x97he',\n",
       " '248',\n",
       " '248 x93with',\n",
       " '248 x93with kings',\n",
       " '249',\n",
       " '249 would',\n",
       " '249 would seem',\n",
       " '25',\n",
       " '25 days',\n",
       " '25 days bartleby',\n",
       " '250',\n",
       " '250 ah',\n",
       " '250 ah bartleby',\n",
       " '26',\n",
       " '26 x93bartleby',\n",
       " '26 x93bartleby quick',\n",
       " '27',\n",
       " '27 heard',\n",
       " '27 heard slow',\n",
       " '28',\n",
       " '28 x93what',\n",
       " '28 x93what wanted',\n",
       " '29',\n",
       " '29 x93the',\n",
       " '29 x93the copies',\n",
       " '30',\n",
       " '30 x93i',\n",
       " '30 x93i would',\n",
       " '31',\n",
       " '31 moments',\n",
       " '31 moments turned',\n",
       " '32',\n",
       " '32 x93why',\n",
       " '32 x93why refuse',\n",
       " '33',\n",
       " '33 x93i',\n",
       " '33 x93i would',\n",
       " '34',\n",
       " '34 man',\n",
       " '34 man flown',\n",
       " '35',\n",
       " '35 evening',\n",
       " '35 evening news',\n",
       " '35 x93these',\n",
       " '35 x93these copies',\n",
       " '36',\n",
       " '36 x93i',\n",
       " '36 x93i prefer',\n",
       " '37',\n",
       " '37 x93you',\n",
       " '37 x93you decided',\n",
       " '38',\n",
       " '38 briefly',\n",
       " '38 briefly gave',\n",
       " '39',\n",
       " '39 seldom',\n",
       " '39 seldom case',\n",
       " '40',\n",
       " '40 x93turkey',\n",
       " '40 x93turkey x94',\n",
       " '41',\n",
       " '41 x93with',\n",
       " '41 x93with submission',\n",
       " '42',\n",
       " '42 x93nippers',\n",
       " '42 x93nippers x94',\n",
       " '43',\n",
       " '43 x93i',\n",
       " '43 x93i think',\n",
       " '44',\n",
       " '44 reader',\n",
       " '44 reader nice',\n",
       " '45',\n",
       " '45 x93ginger',\n",
       " '45 x93ginger nut',\n",
       " '46',\n",
       " '46 x93i',\n",
       " '46 x93i think',\n",
       " '47',\n",
       " '47 x93you',\n",
       " '47 x93you hear',\n",
       " '48',\n",
       " '48 vouchsafed',\n",
       " '48 vouchsafed reply',\n",
       " '49',\n",
       " '49 may',\n",
       " '49 may spring',\n",
       " '49 meanwhile',\n",
       " '49 meanwhile bartleby',\n",
       " '50',\n",
       " '50 days',\n",
       " '50 days passed',\n",
       " '50 recollect',\n",
       " '50 recollect exactly',\n",
       " '52',\n",
       " '52 nothing',\n",
       " '52 nothing aggravates',\n",
       " '53',\n",
       " '53 x93bartleby',\n",
       " '53 x93bartleby x94',\n",
       " '54',\n",
       " '54 x93i',\n",
       " '54 x93i would',\n",
       " '55',\n",
       " '55 x93how',\n",
       " '55 x93how surely',\n",
       " '56',\n",
       " '56 answer',\n",
       " '56 answer 57',\n",
       " '57',\n",
       " '57 threw',\n",
       " '57 threw open',\n",
       " '58',\n",
       " '58 x93he',\n",
       " '58 x93he says',\n",
       " '59',\n",
       " '59 afternoon',\n",
       " '59 afternoon remembered',\n",
       " '60',\n",
       " '60 x93think',\n",
       " '60 x93think x94',\n",
       " '61',\n",
       " '61 saying',\n",
       " '61 saying turkey',\n",
       " '62',\n",
       " '62 x93sit',\n",
       " '62 x93sit turkey',\n",
       " '63',\n",
       " '63 x93excuse',\n",
       " '63 x93excuse decide',\n",
       " '64',\n",
       " '64 x93ah',\n",
       " '64 x93ah x94',\n",
       " '65',\n",
       " '65 x93all',\n",
       " '65 x93all beer',\n",
       " '66',\n",
       " '66 x93you',\n",
       " '66 x93you refer',\n",
       " '67',\n",
       " '67 closed',\n",
       " '67 closed doors',\n",
       " '68',\n",
       " '68 x93bartleby',\n",
       " '68 x93bartleby x94',\n",
       " '69',\n",
       " '69 x93i',\n",
       " '69 x93i would',\n",
       " '70',\n",
       " '70 x93you',\n",
       " '70 x93you x94',\n",
       " '71',\n",
       " '71 x93i',\n",
       " '71 x93i prefer',\n",
       " '72',\n",
       " '72 staggered',\n",
       " '72 staggered desk',\n",
       " '73',\n",
       " '73 x93bartleby',\n",
       " '73 x93bartleby x94',\n",
       " '74',\n",
       " '74 answer',\n",
       " '74 answer 75',\n",
       " '75',\n",
       " '75 x93bartleby',\n",
       " '75 x93bartleby x94',\n",
       " '76',\n",
       " '76 answer',\n",
       " '76 answer 77',\n",
       " '77',\n",
       " '77 x93bartleby',\n",
       " '77 x93bartleby x94',\n",
       " '78',\n",
       " '78 like',\n",
       " '78 like ghost',\n",
       " '79',\n",
       " '79 x93go',\n",
       " '79 x93go next',\n",
       " '80',\n",
       " '80 x93i',\n",
       " '80 x93i prefer',\n",
       " '81',\n",
       " '81 x93very',\n",
       " '81 x93very good',\n",
       " '82',\n",
       " '82 shall',\n",
       " '82 shall acknowledge',\n",
       " '83',\n",
       " '83 days',\n",
       " '83 days passed',\n",
       " '84',\n",
       " '84 must',\n",
       " '84 must said',\n",
       " '85',\n",
       " '85 one',\n",
       " '85 one sunday',\n",
       " '86',\n",
       " '86 utterly',\n",
       " '86 utterly unsurmised',\n",
       " '87',\n",
       " '87 nevertheless',\n",
       " '87 nevertheless mind',\n",
       " '88',\n",
       " '88 first',\n",
       " '88 first time',\n",
       " '89',\n",
       " '89 suddenly',\n",
       " '89 suddenly attracted',\n",
       " '90',\n",
       " '90 mean',\n",
       " '90 mean mischief',\n",
       " '91',\n",
       " '91 recalled',\n",
       " '91 recalled quiet',\n",
       " '911',\n",
       " '911 better',\n",
       " '911 better come',\n",
       " '911 x94',\n",
       " '911 x94 fat',\n",
       " '92',\n",
       " '92 revolving',\n",
       " '92 revolving things',\n",
       " '93',\n",
       " '93 accomplish',\n",
       " '93 accomplish purpose',\n",
       " '94',\n",
       " '94 next',\n",
       " '94 next morning',\n",
       " '95',\n",
       " '95 x93bartleby',\n",
       " '95 x93bartleby x94',\n",
       " '96',\n",
       " '96 reply',\n",
       " '96 reply 97',\n",
       " '97',\n",
       " '97 x93bartleby',\n",
       " '97 x93bartleby x94',\n",
       " '98',\n",
       " '98 upon',\n",
       " '98 upon noiselessly',\n",
       " '99',\n",
       " '99 x93will',\n",
       " '99 x93will tell',\n",
       " 'aback',\n",
       " 'aback rude',\n",
       " 'aback rude speech',\n",
       " 'abandon',\n",
       " 'abandon man',\n",
       " 'abandon man x94',\n",
       " 'abandon ndinner',\n",
       " 'abandon ndinner going',\n",
       " 'abandoned',\n",
       " 'abandoned black',\n",
       " 'abandoned black started',\n",
       " 'abandoned graduate',\n",
       " 'abandoned graduate students',\n",
       " 'abandonment',\n",
       " 'abandonment poor',\n",
       " 'abandonment poor people',\n",
       " 'abate',\n",
       " 'abate rashness',\n",
       " 'abate rashness obstreperousness',\n",
       " 'abated',\n",
       " 'abated quietude',\n",
       " 'abated quietude courtesy',\n",
       " 'aberration',\n",
       " 'aberration might',\n",
       " 'aberration might yet',\n",
       " 'aberrations',\n",
       " 'aberrations buried',\n",
       " 'aberrations buried beneath',\n",
       " 'abide',\n",
       " 'abide 170',\n",
       " 'abide 170 shall',\n",
       " 'abiding',\n",
       " 'abiding daylight',\n",
       " 'abiding daylight passed',\n",
       " 'abiding place',\n",
       " 'abiding place home',\n",
       " 'able',\n",
       " 'able take',\n",
       " 'able take care',\n",
       " 'able win',\n",
       " 'able win little',\n",
       " 'abloom',\n",
       " 'abloom even',\n",
       " 'abloom even dark',\n",
       " 'abode',\n",
       " 'abode offered',\n",
       " 'abode offered assist',\n",
       " 'abode service',\n",
       " 'abode service fail',\n",
       " 'abominable',\n",
       " 'abominable misery',\n",
       " 'abominable misery nthis',\n",
       " 'aboveground',\n",
       " 'aboveground blasted',\n",
       " 'aboveground blasted black',\n",
       " 'abridge',\n",
       " 'abridge labors',\n",
       " 'abridge labors short',\n",
       " 'abroad',\n",
       " 'abroad among',\n",
       " 'abroad among modern',\n",
       " 'abrogation',\n",
       " 'abrogation office',\n",
       " 'abrogation office master',\n",
       " 'abrupt',\n",
       " 'abrupt cruel',\n",
       " 'abrupt cruel lydia',\n",
       " 'abrupt departure',\n",
       " 'abrupt departure seem',\n",
       " 'abruptly',\n",
       " 'abruptly called',\n",
       " 'abruptly called bartleby',\n",
       " 'abruptly crow',\n",
       " 'abruptly crow pluck',\n",
       " 'abruptly pity',\n",
       " 'abruptly pity cried',\n",
       " 'abruptly way',\n",
       " 'abruptly way gretta',\n",
       " 'absconded',\n",
       " 'absconded make',\n",
       " 'absconded make merry',\n",
       " 'absence',\n",
       " 'absence would',\n",
       " 'absence would pause',\n",
       " 'absent',\n",
       " 'absent faces',\n",
       " 'absent faces miss',\n",
       " 'absent great',\n",
       " 'absent great hurry',\n",
       " 'absent mindedly',\n",
       " 'absent mindedly put',\n",
       " 'absent mindedness',\n",
       " 'absent mindedness 151',\n",
       " 'absolute',\n",
       " 'absolute certainty',\n",
       " 'absolute certainty maybe',\n",
       " 'absolute may',\n",
       " 'absolute may even',\n",
       " 'absolutely',\n",
       " 'absolutely alone',\n",
       " 'absolutely alone universe',\n",
       " 'absolutely furious',\n",
       " 'absolutely furious x93you',\n",
       " 'absolutely idle',\n",
       " 'absolutely idle averse',\n",
       " 'absolutely x92t',\n",
       " 'absolutely x92t x92s',\n",
       " 'absolution',\n",
       " 'absolution x92t',\n",
       " 'absolution x92t nand',\n",
       " 'abstaining',\n",
       " 'abstaining writing',\n",
       " 'abstaining writing urged',\n",
       " 'abstract',\n",
       " 'abstract world',\n",
       " 'abstract world eliminating',\n",
       " 'abstracted',\n",
       " 'abstracted know',\n",
       " 'abstracted know could',\n",
       " 'abstractedly',\n",
       " 'abstractedly go',\n",
       " 'abstractedly go away',\n",
       " 'absurd',\n",
       " 'absurd said',\n",
       " 'absurd said asked',\n",
       " 'absurd visible',\n",
       " 'absurd visible means',\n",
       " 'absurdly',\n",
       " 'absurdly concluded',\n",
       " 'absurdly concluded knowing',\n",
       " 'absurdly low',\n",
       " 'absurdly low price',\n",
       " 'abundance',\n",
       " 'abundance aisles',\n",
       " 'abundance aisles gaudy',\n",
       " 'abundance harvest',\n",
       " 'abundance harvest kindly',\n",
       " 'abundance laughter',\n",
       " 'abundance laughter freddy',\n",
       " 'abuts',\n",
       " 'abuts bo',\n",
       " 'abuts bo diddley',\n",
       " 'academy',\n",
       " 'academy gave',\n",
       " 'academy gave pupils',\n",
       " 'academy piece',\n",
       " 'academy piece full',\n",
       " 'academy sciences',\n",
       " 'academy sciences packed',\n",
       " 'accent',\n",
       " 'accent prefer',\n",
       " 'accent prefer plain',\n",
       " 'accent young',\n",
       " 'accent young ladies',\n",
       " 'accept',\n",
       " 'accept festival',\n",
       " 'accept festival city',\n",
       " 'accept happen',\n",
       " 'accept happen x93i',\n",
       " 'accept yet',\n",
       " 'accept yet tears',\n",
       " 'acceptance',\n",
       " 'acceptance helplessness',\n",
       " 'acceptance helplessness perhaps',\n",
       " 'acceptance mail',\n",
       " 'acceptance mail phone',\n",
       " 'acceptance nmy',\n",
       " 'acceptance nmy mother',\n",
       " 'accepted',\n",
       " 'accepted glass',\n",
       " 'accepted glass mechanically',\n",
       " 'accepted living',\n",
       " 'accepted living mean',\n",
       " 'accepting',\n",
       " 'accepting loss',\n",
       " 'accepting loss one',\n",
       " 'access',\n",
       " 'access page',\n",
       " 'access page x97hey',\n",
       " 'accessible',\n",
       " 'accessible common',\n",
       " 'accessible common prisoners',\n",
       " 'accessible stand',\n",
       " 'accessible stand trees',\n",
       " 'accident',\n",
       " 'accident oxford',\n",
       " 'accident oxford x94',\n",
       " 'accident sites',\n",
       " 'accident sites funeral',\n",
       " 'accidentally',\n",
       " 'accidentally knee',\n",
       " 'accidentally knee knocked',\n",
       " 'accidents',\n",
       " 'accidents cancerous',\n",
       " 'accidents cancerous growths',\n",
       " 'accidents one',\n",
       " 'accidents one bees',\n",
       " 'acclamation',\n",
       " 'acclamation followed',\n",
       " 'acclamation followed taken',\n",
       " 'accomplish',\n",
       " 'accomplish purpose',\n",
       " 'accomplish purpose going',\n",
       " 'accomplish waits',\n",
       " 'accomplish waits x92s',\n",
       " 'accomplishing',\n",
       " 'accomplishing great',\n",
       " 'accomplishing great deal',\n",
       " 'accord',\n",
       " 'accord perhaps',\n",
       " 'accord perhaps thoughts',\n",
       " 'accord take',\n",
       " 'accord take would',\n",
       " 'accord would',\n",
       " 'accord would emerge',\n",
       " 'according',\n",
       " 'according colours',\n",
       " 'according colours uniforms',\n",
       " 'according common',\n",
       " 'according common usage',\n",
       " 'according custom',\n",
       " 'according custom legal',\n",
       " 'according humor',\n",
       " 'according humor threw',\n",
       " 'according textbooks',\n",
       " 'according textbooks x92s',\n",
       " 'accordingly',\n",
       " 'accordingly disinterested',\n",
       " 'accordingly disinterested persons',\n",
       " 'accordingly next',\n",
       " 'accordingly next day',\n",
       " 'accordingly returned',\n",
       " 'accordingly returned tenement',\n",
       " 'accordingly turkey',\n",
       " 'accordingly turkey nippers',\n",
       " 'accosted',\n",
       " 'accosted excessive',\n",
       " 'accosted excessive warmth',\n",
       " 'accosted jerking',\n",
       " 'accosted jerking thumb',\n",
       " 'account',\n",
       " 'account dispatched',\n",
       " 'account dispatched trivial',\n",
       " 'account fearful',\n",
       " 'account fearful exposed',\n",
       " 'account hive',\n",
       " 'account hive nthe',\n",
       " 'account occasioned',\n",
       " 'account occasioned uneasiness',\n",
       " 'account thirty',\n",
       " 'account thirty two',\n",
       " 'account x94',\n",
       " 'account x94 original',\n",
       " 'accuracy',\n",
       " 'accuracy copy',\n",
       " 'accuracy copy two',\n",
       " 'accuracy imperative',\n",
       " 'accuracy imperative things',\n",
       " 'accuracy nstartled',\n",
       " 'accuracy nstartled gave',\n",
       " 'accurate',\n",
       " 'accurate maps',\n",
       " 'accurate maps provinces',\n",
       " 'accused',\n",
       " 'accused gus',\n",
       " 'accused gus anything',\n",
       " 'accused ruining',\n",
       " 'accused ruining birthday',\n",
       " 'ace',\n",
       " 'ace dismissing',\n",
       " 'ace dismissing mollified',\n",
       " 'ace spades',\n",
       " 'ace spades maid',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.feature_extraction.text.TfidfVectorizer"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 99464)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=27, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components=27, n_iter=100)\n",
    "lsa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00154377, 0.00092266, 0.00092266, ..., 0.00114066, 0.00114066,\n",
       "       0.00114066])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 (default, Nov 23 2017, 16:37:01) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 0:\n",
      "x94\n",
      "x92s\n",
      "x92t\n",
      "said\n",
      "zofia\n",
      "gus\n",
      "jude\n",
      "x93i\n",
      "bartleby\n",
      "like\n",
      " \n",
      "Concept 1:\n",
      "said\n",
      "gabriel\n",
      "hunter\n",
      "old\n",
      "aunt\n",
      "george\n",
      "nursery\n",
      "kate\n",
      "nthe\n",
      "lions\n",
      " \n",
      "Concept 2:\n",
      "alma\n",
      "jimmy\n",
      "greta\n",
      "x92s\n",
      "smiley\n",
      "omelas\n",
      "x92t\n",
      "walk\n",
      "frog\n",
      "ass\n",
      " \n",
      "Concept 3:\n",
      "wasps\n",
      "hive\n",
      "wasp\n",
      "bees\n",
      "queen\n",
      "foundress\n",
      "paper\n",
      "nest\n",
      "maps\n",
      "anarchists\n",
      " \n",
      "Concept 4:\n",
      "smiley\n",
      "frog\n",
      "feller\n",
      "bet\n",
      "dan\n",
      "leonidas\n",
      "leonidas smiley\n",
      "wheeler\n",
      "would\n",
      "omelas\n",
      " \n",
      "Concept 5:\n",
      "amontillado\n",
      "ugh\n",
      "fortunato\n",
      "ugh ugh\n",
      "ugh ugh ugh\n",
      "wasps\n",
      "hive\n",
      "jimmy\n",
      "greta\n",
      "wasp\n",
      " \n",
      "Concept 6:\n",
      "omelas\n",
      "child\n",
      "amontillado\n",
      "ugh\n",
      "fortunato\n",
      "ugh ugh\n",
      "ugh ugh ugh\n",
      "upon\n",
      "happiness\n",
      "festival\n",
      " \n",
      "Concept 7:\n",
      "jimmy\n",
      "greta\n",
      "nolan\n",
      "greta x92s\n",
      "jimmy x92s\n",
      "njimmy\n",
      "jimmy nolan\n",
      "broads\n",
      "ngreta\n",
      "hands\n",
      " \n",
      "Concept 8:\n",
      "jimmy\n",
      "greta\n",
      "alma\n",
      "gabriel\n",
      "aunt\n",
      "nolan\n",
      "husband\n",
      "greta x92s\n",
      "hands\n",
      "ass\n",
      " \n",
      "Concept 9:\n",
      "walk\n",
      "neighborhood\n",
      "nuns\n",
      "swans\n",
      "night\n",
      "homeless\n",
      "house\n",
      "pond\n",
      "amontillado\n",
      "houses\n",
      " \n",
      "Concept 10:\n",
      "george\n",
      "nursery\n",
      "lions\n",
      "jimmy\n",
      "greta\n",
      "hadley\n",
      "george hadley\n",
      "peter\n",
      "africa\n",
      "lydia\n",
      " \n",
      "Concept 11:\n",
      "gabriel\n",
      "aunt\n",
      "kate\n",
      "aunt kate\n",
      "miss\n",
      "julia\n",
      "mary jane\n",
      "browne\n",
      "jane\n",
      "mr browne\n",
      " \n",
      "Concept 12:\n",
      "hunter\n",
      "snow\n",
      "truck\n",
      "cabin\n",
      "river\n",
      "wolves\n",
      "maples\n",
      "nthe hunter\n",
      "winter\n",
      "gabriel\n",
      " \n",
      "Concept 13:\n",
      "bartleby\n",
      "turkey\n",
      "nippers\n",
      "x94 said\n",
      "upon\n",
      "x94\n",
      "prefer\n",
      "office\n",
      "would prefer\n",
      "scrivener\n",
      " \n",
      "Concept 14:\n",
      "zofia\n",
      "handbag\n",
      "jake\n",
      "zofia said\n",
      "x94 zofia\n",
      "hill\n",
      "x94 zofia said\n",
      "zofia x92s\n",
      "x94 said\n",
      "scrabble\n",
      " \n",
      "Concept 15:\n",
      "gus\n",
      "ray\n",
      "x92s\n",
      "x92ll\n",
      "x92m\n",
      "ghosh\n",
      "sister\n",
      "mom\n",
      "mary\n",
      "mr ghosh\n",
      " \n",
      "Concept 16:\n",
      "ray\n",
      "ghosh\n",
      "says\n",
      "x94 says\n",
      "mary\n",
      "mr ghosh\n",
      "biz\n",
      "x94\n",
      "zofia\n",
      "x94 ray\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_): \n",
    "    termsInComp = zip (terms,comp)\n",
    "    sortedTerms =  sorted(termsInComp, key=lambda x: x[1], reverse=True) [:10]\n",
    "    print(\"Concept %d:\" % i )\n",
    "    for term in sortedTerms:\n",
    "        print(term[0])\n",
    "    print (\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00154377,  0.00092266,  0.00092266, ...,  0.00114066,\n",
       "         0.00114066,  0.00114066],\n",
       "       [-0.00049844, -0.00054973, -0.00054973, ..., -0.00039736,\n",
       "        -0.00039736, -0.00039736],\n",
       "       [ 0.00057254,  0.00169627,  0.00169627, ..., -0.00035441,\n",
       "        -0.00035441, -0.00035441],\n",
       "       ...,\n",
       "       [ 0.00048684,  0.00066931,  0.00066931, ...,  0.00424437,\n",
       "         0.00424437,  0.00424437],\n",
       "       [-0.00087735, -0.00075964, -0.00075964, ..., -0.00222927,\n",
       "        -0.00222927, -0.00222927],\n",
       "       [-0.00065136, -0.0001929 , -0.0001929 , ...,  0.00068938,\n",
       "         0.00068938,  0.00068938]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "docA = \"the cat sat on my face\"\n",
    "docB = \"the dog sat on my bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowA = docA.split(\" \")   #bow = bag of words\n",
    "bowB = docB.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'dog', 'sat', 'on', 'my', 'bed'] "
     ]
    }
   ],
   "source": [
    "print(bowB, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSet= set(bowA).union(set(bowB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bed', 'cat', 'dog', 'face', 'my', 'on', 'sat', 'the'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(wordSet, 0)\n",
    "wordDictB = dict.fromkeys(wordSet, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bowA:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "for word in bowB:\n",
    "    wordDictB[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bed': 0, 'cat': 1, 'dog': 0, 'face': 1, 'my': 1, 'on': 1, 'sat': 1, 'the': 1}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bed</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>face</th>\n",
       "      <th>my</th>\n",
       "      <th>on</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bed  cat  dog  face  my  on  sat  the\n",
       "0    0    1    0     1   1   1    1    1\n",
       "1    1    0    1     0   1   1    1    1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfBowA = computeTF(wordDictA, bowA)\n",
    "tfBowB = computeTF(wordDictB, bowB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    #counts the number of documents that contain a word w\n",
    "    idfDict = dict.fromkeys(docList[0].keys(),0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] +=1\n",
    "                \n",
    "    #divide N by denominator above, take the log of that\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word]= math.log(N / float(val)) \n",
    "\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA =  computeTFIDF(tfBowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfBowB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bed</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>face</th>\n",
       "      <th>my</th>\n",
       "      <th>on</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bed       cat       dog      face   my   on  sat  the\n",
       "0  0.000000  0.115525  0.000000  0.115525  0.0  0.0  0.0  0.0\n",
       "1  0.115525  0.000000  0.115525  0.000000  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([tfidfBowA, tfidfBowB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
