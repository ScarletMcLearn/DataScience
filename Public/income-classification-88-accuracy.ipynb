{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992d1122",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-16T18:03:26.808163Z",
     "iopub.status.busy": "2024-10-16T18:03:26.806850Z",
     "iopub.status.idle": "2024-10-16T18:03:27.832606Z",
     "shell.execute_reply": "2024-10-16T18:03:27.831044Z"
    },
    "papermill": {
     "duration": 1.043224,
     "end_time": "2024-10-16T18:03:27.835764",
     "exception": false,
     "start_time": "2024-10-16T18:03:26.792540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/income-classification/income_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436aef0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:03:27.867192Z",
     "iopub.status.busy": "2024-10-16T18:03:27.866468Z",
     "iopub.status.idle": "2024-10-16T18:03:43.860626Z",
     "shell.execute_reply": "2024-10-16T18:03:43.858472Z"
    },
    "papermill": {
     "duration": 16.010525,
     "end_time": "2024-10-16T18:03:43.863859",
     "exception": false,
     "start_time": "2024-10-16T18:03:27.853334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.12.3)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.14.1)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.5.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12dbc1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:03:43.890023Z",
     "iopub.status.busy": "2024-10-16T18:03:43.889530Z",
     "iopub.status.idle": "2024-10-16T18:03:46.916379Z",
     "shell.execute_reply": "2024-10-16T18:03:46.915295Z"
    },
    "papermill": {
     "duration": 3.043544,
     "end_time": "2024-10-16T18:03:46.919070",
     "exception": false,
     "start_time": "2024-10-16T18:03:43.875526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/income-classification/income_evaluation.csv\n",
      "Original class distribution:\n",
      " income\n",
      "0    19778\n",
      "1     6270\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution:\n",
      " income\n",
      "1    19778\n",
      "0    19778\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your original DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    fn = []\n",
    "    for filename in filenames:\n",
    "        fn.append(os.path.join(dirname, filename))\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "fn\n",
    "\n",
    "df_copy_2 = pd.read_csv(fn[0])\n",
    "\n",
    "# df_copy_2 = df.copy()\n",
    "\n",
    "# Define the mapping for the workclass column\n",
    "workclass_mapping = {\n",
    "    ' Private': 'Private',\n",
    "    ' Self-emp-not-inc': 'Private',\n",
    "    ' Self-emp-inc': 'Private',\n",
    "    ' Without-pay': 'Private',\n",
    "    ' Federal-gov': 'Gov',\n",
    "    ' Local-gov': 'Gov',\n",
    "    ' State-gov': 'Gov',\n",
    "    ' ?' : ' Never-worked'\n",
    "}\n",
    "\n",
    "# Define the mapping for the education column\n",
    "education_mapping = {\n",
    "    ' Bachelors': 'Graduate',\n",
    "    ' Some-college': 'Not Graduate',\n",
    "    ' 11th grade': 'Not Graduate',\n",
    "    ' HS-grad': 'Not Graduate',\n",
    "    ' Prof-school': 'Graduate',\n",
    "    ' Assoc-acdm': 'Graduate',\n",
    "    ' Assoc-voc': 'Graduate',\n",
    "    ' 9th grade': 'Not Graduate',\n",
    "    ' 7th-8th grade': 'Not Graduate',\n",
    "    ' 12th grade': 'Not Graduate',\n",
    "    ' Masters': 'Graduate',\n",
    "    ' 1st-4th grade': 'Not Graduate',\n",
    "    ' 10th grade': 'Not Graduate',\n",
    "    ' Doctorate': 'Graduate',\n",
    "    ' 5th-6th grade': 'Not Graduate',\n",
    "    ' Preschool': 'Not Graduate',\n",
    "    ' 11th': 'Not Graduate',\n",
    "    ' 9th': 'Not Graduate',\n",
    "    ' 7th-8th': 'Not Graduate',\n",
    "       ' 5th-6th': 'Not Graduate',\n",
    "     ' 10th': 'Not Graduate',\n",
    "    ' 1st-4th': 'Not Graduate',\n",
    "    ' 12th': 'Not Graduate',\n",
    "}\n",
    "\n",
    "marital_status_mapping = {\n",
    "    ' Married-civ-spouse': 'Married',\n",
    "    ' Married-AF-spouse': 'Married',\n",
    "    ' Married-spouse-absent': 'Married',\n",
    "    ' Divorced': 'Not Married',\n",
    "    ' Never-married': 'Not Married',\n",
    "    ' Separated': 'Not Married',\n",
    "    ' Widowed': 'Not Married'\n",
    "}\n",
    "\n",
    "# Define the mapping for the occupation column\n",
    "occupation_mapping = {\n",
    "    ' Tech-support': 'White Collar',\n",
    "    ' Craft-repair': 'Blue Collar',\n",
    "    ' Other-service': 'Pink Collar',\n",
    "    ' Sales': 'White Collar',\n",
    "    ' Exec-managerial': 'White Collar',\n",
    "    ' Prof-specialty': 'White Collar',\n",
    "    ' Handlers-cleaners': 'Blue Collar',\n",
    "    ' Machine-op-inspct': 'Blue Collar',\n",
    "    ' Adm-clerical': 'White Collar',\n",
    "    ' Farming-fishing': 'Blue Collar',\n",
    "    ' Transport-moving': 'Blue Collar',\n",
    "    ' Priv-house-serv': 'Pink Collar',\n",
    "    ' Protective-serv': 'Blue Collar',\n",
    "    ' Armed-Forces': 'Blue Collar',\n",
    "    ' ?' : 'Blue Collar'\n",
    "}\n",
    "\n",
    "\n",
    "# Define the mapping for the relationship column\n",
    "relationship_mapping = {\n",
    "    ' Wife': 'Married',\n",
    "    ' Own-child': 'Unmarried',\n",
    "    ' Husband': 'Married',\n",
    "    ' Not-in-family': 'Unmarried',\n",
    "    ' Other-relative': 'Unmarried',\n",
    "    ' Unmarried': 'Unmarried'\n",
    "}\n",
    "\n",
    "\n",
    "# Define the mapping for the race column\n",
    "race_mapping = {\n",
    "    ' White': 'White',\n",
    "    ' Asian-Pac-Islander': 'Not White',\n",
    "    ' Amer-Indian-Eskimo': 'Not White',\n",
    "    ' Other': 'Not White',\n",
    "    ' Black': 'Not White'\n",
    "}\n",
    "\n",
    "# Define the mapping for the native-country column\n",
    "native_country_mapping = {\n",
    "    ' United-States': 'First World',\n",
    "    ' Cambodia': 'Third World',\n",
    "    ' England': 'First World',\n",
    "    ' Puerto-Rico': 'Third World',\n",
    "    ' Canada': 'First World',\n",
    "    ' Germany': 'First World',\n",
    "    ' Outlying-US(Guam-USVI-etc)': 'First World',\n",
    "    ' India': 'Third World',\n",
    "    ' Japan': 'First World',\n",
    "    ' Greece': 'First World',\n",
    "    ' South': 'Third World',\n",
    "    ' China': 'Second World',\n",
    "    ' Cuba': 'Second World',\n",
    "    ' Iran': 'Third World',\n",
    "    ' Honduras': 'Third World',\n",
    "    ' Philippines': 'Third World',\n",
    "    ' Italy': 'First World',\n",
    "    ' Poland': 'Second World',\n",
    "    ' Jamaica': 'Third World',\n",
    "    ' Vietnam': 'Second World',\n",
    "    ' Mexico': 'Third World',\n",
    "    ' Portugal': 'First World',\n",
    "    ' Ireland': 'First World',\n",
    "    ' France': 'First World',\n",
    "    ' Dominican-Republic': 'Third World',\n",
    "    ' Laos': 'Third World',\n",
    "    ' Ecuador': 'Third World',\n",
    "    ' Taiwan': 'First World',\n",
    "    ' Haiti': 'Third World',\n",
    "    ' Columbia': 'Third World',\n",
    "    ' Hungary': 'Second World',\n",
    "    ' Guatemala': 'Third World',\n",
    "    ' Nicaragua': 'Third World',\n",
    "    ' Scotland': 'First World',\n",
    "    ' Thailand': 'Third World',\n",
    "    ' Yugoslavia': 'Second World',\n",
    "    ' El-Salvador': 'Third World',\n",
    "    ' Trinadad&Tobago': 'Third World',\n",
    "    ' Peru': 'Third World',\n",
    "    ' Hong': 'First World',\n",
    "    ' Holand-Netherlands': 'First World',\n",
    "    \" ?\": 'Third World'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the native-country column\n",
    "df_copy_2[' native-country'] = df_copy_2[' native-country'].map(native_country_mapping).fillna(df_copy_2[' native-country'])\n",
    "\n",
    "# Apply the mapping to the race column\n",
    "df_copy_2[' race'] = df_copy_2[' race'].map(race_mapping).fillna(df_copy_2[' race'])\n",
    "\n",
    "\n",
    "\n",
    "# Apply the mapping to the relationship column\n",
    "df_copy_2[' relationship'] = df_copy_2[' relationship'].map(relationship_mapping).fillna(df_copy_2[' relationship'])\n",
    "\n",
    "# Apply the mapping to the occupation column\n",
    "df_copy_2[' occupation'] = df_copy_2[' occupation'].map(occupation_mapping).fillna(df_copy_2[' occupation'])\n",
    "\n",
    "# Apply the mapping to the education column\n",
    "df_copy_2[' education'] = df_copy_2[' education'].map(education_mapping).fillna(df_copy_2[' education'])\n",
    "\n",
    "# Apply the mapping to the workclass column\n",
    "df_copy_2[' workclass'] = df_copy_2[' workclass'].map(workclass_mapping).fillna(df_copy_2[' workclass'])\n",
    "\n",
    "df_copy_2[' marital-status'] = df_copy_2[' marital-status'].map(marital_status_mapping).fillna(df_copy_2[' marital-status'])\n",
    "\n",
    "df_copy_2[' native-country'].unique()\n",
    "\n",
    "df_copy_2.columns = df_copy_2.columns.str.strip()\n",
    "df_copy_2\n",
    "\n",
    "df_copy_2['income'] = df_copy_2['income'].map({' >50K': 1, ' <=50K': 0})\n",
    "df_copy_2['relationship'] = df_copy_2['relationship'].map({'Married': 1, 'Unmarried': 0})\n",
    "df_copy_2['marital-status'] = df_copy_2['marital-status'].map({'Married': 1, 'Not Married': 0})\n",
    "df_copy_2['education'] = df_copy_2['education'].map({'Graduate': 1, 'Not Graduate': 0})\n",
    "df_copy_2['race'] = df_copy_2['race'].map({'White': 1, 'Not White': 0})\n",
    "df_copy_2['native-country'] = df_copy_2['native-country'].map({'First World':2,\n",
    "                            'Second World': 1, \n",
    "                            'Third World': 0})\n",
    "df_copy_2['occupation'] = df_copy_2['occupation'].map({'White Collar':2,\n",
    "                            'Blue Collar': 1, \n",
    "                            'Pink Collar': 0})\n",
    "df_copy_2['workclass'] = df_copy_2['workclass'].map({'Private':2,\n",
    "                            'Gov': 1, \n",
    "                            ' Never-worked': 0})\n",
    "df_copy_2['sex'] = df_copy_2['sex'].map({' Male': 1, ' Female': 0})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Separate the 'income' column\n",
    "income = df_copy_2['income']\n",
    "df_copy_2 = df_copy_2.drop(columns=['income'])\n",
    "\n",
    "# Apply StandardScaler to the rest of the DataFrame\n",
    "scaler = StandardScaler()\n",
    "df_copy_2 = pd.DataFrame(scaler.fit_transform(df_copy_2), \n",
    "                         columns=df_copy_2.columns)\n",
    "\n",
    "# Add the 'income' column back\n",
    "df_copy_2['income'] = income\n",
    "df_copy_2\n",
    "\n",
    "df_copy_2 = df_copy_2.drop('relationship', axis=1)\n",
    "df_copy_2\n",
    "\n",
    "\n",
    "# Assuming df_copy_2 is your DataFrame and 'income' is the target column\n",
    "X = df_copy_2.drop('income', axis=1)\n",
    "y = df_copy_2['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Original class distribution:\\n\", y_train.value_counts())\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train,\n",
    "                                              y_train)\n",
    "\n",
    "print(\"Resampled class distribution:\\n\", y_train.value_counts())\n",
    "# print(\"Resampled class distribution:\\n\", y_train_res.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55508ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:03:46.946054Z",
     "iopub.status.busy": "2024-10-16T18:03:46.945434Z",
     "iopub.status.idle": "2024-10-16T18:03:46.953714Z",
     "shell.execute_reply": "2024-10-16T18:03:46.952625Z"
    },
    "papermill": {
     "duration": 0.024333,
     "end_time": "2024-10-16T18:03:46.956438",
     "exception": false,
     "start_time": "2024-10-16T18:03:46.932105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.utils import all_estimators\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# # Get all classifier algorithms\n",
    "# classifiers = all_estimators(type_filter='classifier')\n",
    "\n",
    "# # Initialize variables to store the best results\n",
    "# best_test_accuracy = 0\n",
    "# best_train_accuracy_of_best_test = 0  # Train accuracy of the best test accuracy model\n",
    "# best_test_model = None\n",
    "# best_test_params = None\n",
    "\n",
    "# # Loop through each classifier\n",
    "# for name, Classifier in classifiers:\n",
    "#     try:\n",
    "#         # Special handling for ClassifierChain\n",
    "#         clf = Classifier(base_estimator=LogisticRegression()) if name == 'ClassifierChain' else Classifier()\n",
    "\n",
    "#         # Clear the output and print the current model being trained\n",
    "#         clear_output(wait=True)\n",
    "#         print(f\"Currently training: {name}\")\n",
    "#         print(f\"Best Test Accuracy So Far: {best_test_accuracy:.4f} (Model: {best_test_model})\")\n",
    "#         print(f\"Training Accuracy of the Best Test Model So Far: {best_train_accuracy_of_best_test:.4f}\")\n",
    "\n",
    "#         # Train the classifier\n",
    "#         clf.fit(X_train, y_train)\n",
    "\n",
    "#         # Compute training and testing accuracy\n",
    "#         train_accuracy = clf.score(X_train, y_train)\n",
    "#         test_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "#         # Update the best test accuracy and store the corresponding train accuracy\n",
    "#         if test_accuracy > best_test_accuracy:\n",
    "#             best_test_accuracy = test_accuracy\n",
    "#             best_test_model = name\n",
    "#             best_test_params = clf.get_params()\n",
    "#             best_train_accuracy_of_best_test = train_accuracy  # Store train accuracy of the best test model\n",
    "\n",
    "#         # Print the best results so far along with the current model\n",
    "#         clear_output(wait=True)\n",
    "#         print(f\"Currently training: {name}\")\n",
    "#         print(f\"Best Test Accuracy So Far: {best_test_accuracy:.4f} (Model: {best_test_model})\")\n",
    "#         print(f\"Training Accuracy of the Best Test Model So Far: {best_train_accuracy_of_best_test:.4f}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         # Handle classifier failures\n",
    "#         clear_output(wait=True)\n",
    "#         print(f\"{name} failed: {e}\")\n",
    "#         print(f\"Best Test Accuracy So Far: {best_test_accuracy:.4f} (Model: {best_test_model})\")\n",
    "#         print(f\"Training Accuracy of the Best Test Model So Far: {best_train_accuracy_of_best_test:.4f}\")\n",
    "\n",
    "# # Print final results\n",
    "# clear_output(wait=True)\n",
    "# print(\"Final Results:\")\n",
    "# print(f\"Best Test Accuracy: {best_test_accuracy:.4f} (Model: {best_test_model})\")\n",
    "# print(f\"Training Accuracy of the Best Test Model: {best_train_accuracy_of_best_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94e59ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:03:46.982614Z",
     "iopub.status.busy": "2024-10-16T18:03:46.982160Z",
     "iopub.status.idle": "2024-10-16T18:03:46.987428Z",
     "shell.execute_reply": "2024-10-16T18:03:46.986231Z"
    },
    "papermill": {
     "duration": 0.021552,
     "end_time": "2024-10-16T18:03:46.990170",
     "exception": false,
     "start_time": "2024-10-16T18:03:46.968618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final Results:\n",
    "# Best Test Accuracy: 0.8419 (Model: HistGradientBoostingClassifier)\n",
    "# Training Accuracy of the Best Test Model: 0.8875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e3713e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:03:47.018275Z",
     "iopub.status.busy": "2024-10-16T18:03:47.017385Z",
     "iopub.status.idle": "2024-10-16T18:03:47.023159Z",
     "shell.execute_reply": "2024-10-16T18:03:47.021748Z"
    },
    "papermill": {
     "duration": 0.023513,
     "end_time": "2024-10-16T18:03:47.025720",
     "exception": false,
     "start_time": "2024-10-16T18:03:47.002207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d3f4b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:03:47.051464Z",
     "iopub.status.busy": "2024-10-16T18:03:47.051051Z",
     "iopub.status.idle": "2024-10-16T18:03:47.059893Z",
     "shell.execute_reply": "2024-10-16T18:03:47.058756Z"
    },
    "papermill": {
     "duration": 0.024577,
     "end_time": "2024-10-16T18:03:47.062469",
     "exception": false,
     "start_time": "2024-10-16T18:03:47.037892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ceeef73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:03:47.089068Z",
     "iopub.status.busy": "2024-10-16T18:03:47.088623Z",
     "iopub.status.idle": "2024-10-16T18:13:45.669457Z",
     "shell.execute_reply": "2024-10-16T18:13:45.667520Z"
    },
    "papermill": {
     "duration": 598.597472,
     "end_time": "2024-10-16T18:13:45.672306",
     "exception": false,
     "start_time": "2024-10-16T18:03:47.074834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Parameters: {'l2_regularization': 1.0, 'learning_rate': 0.2, 'max_depth': 10, 'max_iter': 200, 'max_leaf_nodes': 63, 'min_samples_leaf': 20}\n",
      "Best Training Accuracy: 0.9300\n",
      "Best Test Accuracy: 0.8434\n",
      "\u001b[H\u001b[2JCross-Validation Scores: [0.77616279 0.86057388 0.91252686 0.91884717 0.91240046]\n",
      "Mean CV Accuracy: 0.8761\n",
      "Standard Deviation of CV Accuracy: 0.0542\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "# Step 1: Copy the DataFrame\n",
    "# df_copy = df.copy()\n",
    "\n",
    "# # Step 2: Ordinally encode non-numeric columns\n",
    "# ordinal_encoder = OrdinalEncoder()\n",
    "# non_numeric_cols = df_copy.select_dtypes(include=['object']).columns\n",
    "# df_copy[non_numeric_cols] = ordinal_encoder.fit_transform(df_copy[non_numeric_cols])\n",
    "\n",
    "# # Step 3: Normalize all columns\n",
    "# scaler = MinMaxScaler()\n",
    "# df_copy[df_copy.columns] = scaler.fit_transform(df_copy)\n",
    "\n",
    "\n",
    "# df_copy\n",
    "\n",
    "\n",
    "# x = df_copy.drop(' income', axis=1)\n",
    "# y = df_copy[' income']\n",
    "\n",
    "\n",
    "\n",
    "# columns_to_keep = [' relationship', ' education-num',\n",
    "#                    ]\n",
    "\n",
    "# # # Select only the specified columns\n",
    "# x = x[columns_to_keep]\n",
    "# \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "# If not, you can split your data like this:\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_iter': [100, 200],\n",
    "    'max_leaf_nodes': [31, 63],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_leaf': [20, 50],\n",
    "    'l2_regularization': [0.0, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = HistGradientBoostingClassifier()\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the best parameters and accuracies\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Best Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Store the best model in a variable\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Function to clear the console\n",
    "def clear_console():\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')\n",
    "\n",
    "# Perform k-fold cross-validation and print the results\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "clear_console()\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of CV Accuracy: {np.std(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "938412de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:13:45.700220Z",
     "iopub.status.busy": "2024-10-16T18:13:45.699214Z",
     "iopub.status.idle": "2024-10-16T18:14:00.598147Z",
     "shell.execute_reply": "2024-10-16T18:14:00.596230Z"
    },
    "papermill": {
     "duration": 14.916324,
     "end_time": "2024-10-16T18:14:00.601178",
     "exception": false,
     "start_time": "2024-10-16T18:13:45.684854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_tuner in /opt/conda/lib/python3.10/site-packages (1.4.7)\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (3.3.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (21.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (2.32.3)\r\n",
      "Requirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (1.0.5)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (1.26.4)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (3.11.0)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.3.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras_tuner) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (2024.8.30)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras->keras_tuner) (4.12.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras_tuner) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras_tuner) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7650dd71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:00.631533Z",
     "iopub.status.busy": "2024-10-16T18:14:00.630115Z",
     "iopub.status.idle": "2024-10-16T18:14:00.698350Z",
     "shell.execute_reply": "2024-10-16T18:14:00.696189Z"
    },
    "papermill": {
     "duration": 0.086893,
     "end_time": "2024-10-16T18:14:00.701451",
     "exception": false,
     "start_time": "2024-10-16T18:14:00.614558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_test and y_test are defined\n",
    "smote = SMOTE(random_state=42)\n",
    "X_test, y_test = smote.fit_resample(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1abcec75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:00.729844Z",
     "iopub.status.busy": "2024-10-16T18:14:00.729373Z",
     "iopub.status.idle": "2024-10-16T18:14:00.742518Z",
     "shell.execute_reply": "2024-10-16T18:14:00.741030Z"
    },
    "papermill": {
     "duration": 0.030874,
     "end_time": "2024-10-16T18:14:00.745581",
     "exception": false,
     "start_time": "2024-10-16T18:14:00.714707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Combine the training and resampled test data\n",
    "X_combined = pd.concat([X_train, X_test], axis=0)\n",
    "y_combined = pd.concat([y_train, y_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd145ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:00.776414Z",
     "iopub.status.busy": "2024-10-16T18:14:00.775738Z",
     "iopub.status.idle": "2024-10-16T18:14:00.807644Z",
     "shell.execute_reply": "2024-10-16T18:14:00.805696Z"
    },
    "papermill": {
     "duration": 0.050342,
     "end_time": "2024-10-16T18:14:00.810804",
     "exception": false,
     "start_time": "2024-10-16T18:14:00.760462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_new, X_temp, y_train_new, y_temp = train_test_split(X_combined, y_combined, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba99fcb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:00.839447Z",
     "iopub.status.busy": "2024-10-16T18:14:00.838842Z",
     "iopub.status.idle": "2024-10-16T18:14:00.845584Z",
     "shell.execute_reply": "2024-10-16T18:14:00.844060Z"
    },
    "papermill": {
     "duration": 0.025037,
     "end_time": "2024-10-16T18:14:00.849478",
     "exception": false,
     "start_time": "2024-10-16T18:14:00.824441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_combined = None\n",
    "X_combined = None\n",
    "X_train_new = None\n",
    "y_train_new = None\n",
    "X_temp = None\n",
    "y_temp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547347d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:00.878731Z",
     "iopub.status.busy": "2024-10-16T18:14:00.878264Z",
     "iopub.status.idle": "2024-10-16T18:14:00.910525Z",
     "shell.execute_reply": "2024-10-16T18:14:00.909235Z"
    },
    "papermill": {
     "duration": 0.049652,
     "end_time": "2024-10-16T18:14:00.913302",
     "exception": false,
     "start_time": "2024-10-16T18:14:00.863650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.409205</td>\n",
       "      <td>-1.377146</td>\n",
       "      <td>0.079628</td>\n",
       "      <td>1.447871</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.948296</td>\n",
       "      <td>0.888477</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>-1.422331</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>0.774468</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.189267</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>-0.978882</td>\n",
       "      <td>1.447871</td>\n",
       "      <td>0.357340</td>\n",
       "      <td>1.054523</td>\n",
       "      <td>0.888477</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>4.466257</td>\n",
       "      <td>0.774468</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.423610</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>0.125636</td>\n",
       "      <td>-0.690669</td>\n",
       "      <td>-1.974858</td>\n",
       "      <td>-0.948296</td>\n",
       "      <td>-0.598834</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.288956</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>-0.090843</td>\n",
       "      <td>1.447871</td>\n",
       "      <td>0.357340</td>\n",
       "      <td>1.054523</td>\n",
       "      <td>-0.598834</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>0.450509</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.849080</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>0.853577</td>\n",
       "      <td>-0.690669</td>\n",
       "      <td>-0.031360</td>\n",
       "      <td>-0.948296</td>\n",
       "      <td>-2.086146</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39551</th>\n",
       "      <td>2.743199</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>0.291132</td>\n",
       "      <td>1.447871</td>\n",
       "      <td>1.393938</td>\n",
       "      <td>1.054523</td>\n",
       "      <td>0.888477</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>5.598696</td>\n",
       "      <td>-0.359471</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39552</th>\n",
       "      <td>-0.033510</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>0.427272</td>\n",
       "      <td>1.447871</td>\n",
       "      <td>1.516521</td>\n",
       "      <td>1.054523</td>\n",
       "      <td>0.888477</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>4.689607</td>\n",
       "      <td>1.584366</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39553</th>\n",
       "      <td>1.129915</td>\n",
       "      <td>-1.377146</td>\n",
       "      <td>-1.045764</td>\n",
       "      <td>1.447871</td>\n",
       "      <td>1.620809</td>\n",
       "      <td>0.552808</td>\n",
       "      <td>0.888477</td>\n",
       "      <td>-2.421192</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>2.234814</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.116583</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39554</th>\n",
       "      <td>0.906932</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>-0.436477</td>\n",
       "      <td>-0.690669</td>\n",
       "      <td>-0.171023</td>\n",
       "      <td>-0.948296</td>\n",
       "      <td>0.888477</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>-1.422331</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>0.224018</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39555</th>\n",
       "      <td>-0.257985</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>0.695959</td>\n",
       "      <td>1.447871</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>1.054523</td>\n",
       "      <td>0.888477</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.216660</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0.295335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39556 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  education-num  \\\n",
       "0     -0.409205  -1.377146  0.079628   1.447871       1.134739   \n",
       "1     -0.189267   0.451318 -0.978882   1.447871       0.357340   \n",
       "2      1.423610   0.451318  0.125636  -0.690669      -1.974858   \n",
       "3     -1.288956   0.451318 -0.090843   1.447871       0.357340   \n",
       "4     -0.849080   0.451318  0.853577  -0.690669      -0.031360   \n",
       "...         ...        ...       ...        ...            ...   \n",
       "39551  2.743199   0.451318  0.291132   1.447871       1.393938   \n",
       "39552 -0.033510   0.451318  0.427272   1.447871       1.516521   \n",
       "39553  1.129915  -1.377146 -1.045764   1.447871       1.620809   \n",
       "39554  0.906932   0.451318 -0.436477  -0.690669      -0.171023   \n",
       "39555 -0.257985   0.451318  0.695959   1.447871       1.134739   \n",
       "\n",
       "       marital-status  occupation      race       sex  capital-gain  \\\n",
       "0           -0.948296    0.888477  0.413020 -1.422331     -0.145920   \n",
       "1            1.054523    0.888477  0.413020  0.703071     -0.145920   \n",
       "2           -0.948296   -0.598834  0.413020  0.703071     -0.145920   \n",
       "3            1.054523   -0.598834  0.413020  0.703071     -0.145920   \n",
       "4           -0.948296   -2.086146  0.413020  0.703071     -0.145920   \n",
       "...               ...         ...       ...       ...           ...   \n",
       "39551        1.054523    0.888477  0.413020  0.703071     -0.145920   \n",
       "39552        1.054523    0.888477  0.413020  0.703071     -0.145920   \n",
       "39553        0.552808    0.888477 -2.421192  0.703071      2.234814   \n",
       "39554       -0.948296    0.888477  0.413020 -1.422331     -0.145920   \n",
       "39555        1.054523    0.888477  0.413020  0.703071     -0.145920   \n",
       "\n",
       "       capital-loss  hours-per-week  native-country  \n",
       "0         -0.216660        0.774468        0.295335  \n",
       "1          4.466257        0.774468        0.295335  \n",
       "2         -0.216660       -0.035429        0.295335  \n",
       "3         -0.216660        0.450509        0.295335  \n",
       "4         -0.216660       -0.035429        0.295335  \n",
       "...             ...             ...             ...  \n",
       "39551      5.598696       -0.359471        0.295335  \n",
       "39552      4.689607        1.584366        0.295335  \n",
       "39553     -0.216660       -0.116583        0.295335  \n",
       "39554     -0.216660        0.224018        0.295335  \n",
       "39555     -0.216660       -0.035429        0.295335  \n",
       "\n",
       "[39556 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00e0f1b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:00.942318Z",
     "iopub.status.busy": "2024-10-16T18:14:00.941857Z",
     "iopub.status.idle": "2024-10-16T18:14:00.952140Z",
     "shell.execute_reply": "2024-10-16T18:14:00.950744Z"
    },
    "papermill": {
     "duration": 0.028035,
     "end_time": "2024-10-16T18:14:00.954898",
     "exception": false,
     "start_time": "2024-10-16T18:14:00.926863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "39551    1\n",
       "39552    1\n",
       "39553    1\n",
       "39554    1\n",
       "39555    1\n",
       "Name: income, Length: 39556, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a27a38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:00.985142Z",
     "iopub.status.busy": "2024-10-16T18:14:00.984689Z",
     "iopub.status.idle": "2024-10-16T18:14:00.991570Z",
     "shell.execute_reply": "2024-10-16T18:14:00.990162Z"
    },
    "papermill": {
     "duration": 0.024543,
     "end_time": "2024-10-16T18:14:00.994167",
     "exception": false,
     "start_time": "2024-10-16T18:14:00.969624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# # Simple test model\n",
    "# model = Sequential([\n",
    "#     Dense(32, activation='relu', input_shape=(10,)),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Random test data\n",
    "# # import numpy as np\n",
    "# # X = np.random.rand(100, 10)\n",
    "# # y = np.random.randint(0, 2, 100)\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc854597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:01.024395Z",
     "iopub.status.busy": "2024-10-16T18:14:01.023892Z",
     "iopub.status.idle": "2024-10-16T18:14:01.030407Z",
     "shell.execute_reply": "2024-10-16T18:14:01.029047Z"
    },
    "papermill": {
     "duration": 0.025437,
     "end_time": "2024-10-16T18:14:01.033297",
     "exception": false,
     "start_time": "2024-10-16T18:14:01.007860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras_tuner import RandomSearch\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu', input_dim=X_train.shape[1]))\n",
    "#     for i in range(hp.Int('num_layers', 1, 3)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# tuner = RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_trials=20,\n",
    "#     executions_per_trial=1,\n",
    "#     directory='my_dir',\n",
    "#     project_name='best_model'\n",
    "# )\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# tuner.search(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e3131db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:01.063075Z",
     "iopub.status.busy": "2024-10-16T18:14:01.062608Z",
     "iopub.status.idle": "2024-10-16T18:14:15.830334Z",
     "shell.execute_reply": "2024-10-16T18:14:15.828608Z"
    },
    "papermill": {
     "duration": 14.78604,
     "end_time": "2024-10-16T18:14:15.833461",
     "exception": false,
     "start_time": "2024-10-16T18:14:01.047421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\r\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\r\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (from imblearn) (0.12.3)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.14.1)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.5.0)\r\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\r\n",
      "Installing collected packages: imblearn\r\n",
      "Successfully installed imblearn-0.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "897c958e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:15.865357Z",
     "iopub.status.busy": "2024-10-16T18:14:15.864890Z",
     "iopub.status.idle": "2024-10-16T18:14:16.806093Z",
     "shell.execute_reply": "2024-10-16T18:14:16.804634Z"
    },
    "papermill": {
     "duration": 0.960934,
     "end_time": "2024-10-16T18:14:16.808966",
     "exception": false,
     "start_time": "2024-10-16T18:14:15.848032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/income-classification/income_evaluation.csv\n",
      "Original class distribution:\n",
      " income\n",
      "0    24720\n",
      "1     7841\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution:\n",
      " income\n",
      "0    24720\n",
      "1    24720\n",
      "Name: count, dtype: int64\n",
      "Training set: 34608 samples\n",
      "Validation set: 7416 samples\n",
      "Test set: 7416 samples\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your original DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    fn = []\n",
    "    for filename in filenames:\n",
    "        fn.append(os.path.join(dirname, filename))\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "fn\n",
    "\n",
    "df_copy_2 = pd.read_csv(fn[0])\n",
    "\n",
    "# df_copy_2 = df.copy()\n",
    "\n",
    "# Define the mapping for the workclass column\n",
    "workclass_mapping = {\n",
    "    ' Private': 'Private',\n",
    "    ' Self-emp-not-inc': 'Private',\n",
    "    ' Self-emp-inc': 'Private',\n",
    "    ' Without-pay': 'Private',\n",
    "    ' Federal-gov': 'Gov',\n",
    "    ' Local-gov': 'Gov',\n",
    "    ' State-gov': 'Gov',\n",
    "    ' ?' : ' Never-worked'\n",
    "}\n",
    "\n",
    "# Define the mapping for the education column\n",
    "education_mapping = {\n",
    "    ' Bachelors': 'Graduate',\n",
    "    ' Some-college': 'Not Graduate',\n",
    "    ' 11th grade': 'Not Graduate',\n",
    "    ' HS-grad': 'Not Graduate',\n",
    "    ' Prof-school': 'Graduate',\n",
    "    ' Assoc-acdm': 'Graduate',\n",
    "    ' Assoc-voc': 'Graduate',\n",
    "    ' 9th grade': 'Not Graduate',\n",
    "    ' 7th-8th grade': 'Not Graduate',\n",
    "    ' 12th grade': 'Not Graduate',\n",
    "    ' Masters': 'Graduate',\n",
    "    ' 1st-4th grade': 'Not Graduate',\n",
    "    ' 10th grade': 'Not Graduate',\n",
    "    ' Doctorate': 'Graduate',\n",
    "    ' 5th-6th grade': 'Not Graduate',\n",
    "    ' Preschool': 'Not Graduate',\n",
    "    ' 11th': 'Not Graduate',\n",
    "    ' 9th': 'Not Graduate',\n",
    "    ' 7th-8th': 'Not Graduate',\n",
    "       ' 5th-6th': 'Not Graduate',\n",
    "     ' 10th': 'Not Graduate',\n",
    "    ' 1st-4th': 'Not Graduate',\n",
    "    ' 12th': 'Not Graduate',\n",
    "}\n",
    "\n",
    "marital_status_mapping = {\n",
    "    ' Married-civ-spouse': 'Married',\n",
    "    ' Married-AF-spouse': 'Married',\n",
    "    ' Married-spouse-absent': 'Married',\n",
    "    ' Divorced': 'Not Married',\n",
    "    ' Never-married': 'Not Married',\n",
    "    ' Separated': 'Not Married',\n",
    "    ' Widowed': 'Not Married'\n",
    "}\n",
    "\n",
    "# Define the mapping for the occupation column\n",
    "occupation_mapping = {\n",
    "    ' Tech-support': 'White Collar',\n",
    "    ' Craft-repair': 'Blue Collar',\n",
    "    ' Other-service': 'Pink Collar',\n",
    "    ' Sales': 'White Collar',\n",
    "    ' Exec-managerial': 'White Collar',\n",
    "    ' Prof-specialty': 'White Collar',\n",
    "    ' Handlers-cleaners': 'Blue Collar',\n",
    "    ' Machine-op-inspct': 'Blue Collar',\n",
    "    ' Adm-clerical': 'White Collar',\n",
    "    ' Farming-fishing': 'Blue Collar',\n",
    "    ' Transport-moving': 'Blue Collar',\n",
    "    ' Priv-house-serv': 'Pink Collar',\n",
    "    ' Protective-serv': 'Blue Collar',\n",
    "    ' Armed-Forces': 'Blue Collar',\n",
    "    ' ?' : 'Blue Collar'\n",
    "}\n",
    "\n",
    "\n",
    "# Define the mapping for the relationship column\n",
    "relationship_mapping = {\n",
    "    ' Wife': 'Married',\n",
    "    ' Own-child': 'Unmarried',\n",
    "    ' Husband': 'Married',\n",
    "    ' Not-in-family': 'Unmarried',\n",
    "    ' Other-relative': 'Unmarried',\n",
    "    ' Unmarried': 'Unmarried'\n",
    "}\n",
    "\n",
    "\n",
    "# Define the mapping for the race column\n",
    "race_mapping = {\n",
    "    ' White': 'White',\n",
    "    ' Asian-Pac-Islander': 'Not White',\n",
    "    ' Amer-Indian-Eskimo': 'Not White',\n",
    "    ' Other': 'Not White',\n",
    "    ' Black': 'Not White'\n",
    "}\n",
    "\n",
    "# Define the mapping for the native-country column\n",
    "native_country_mapping = {\n",
    "    ' United-States': 'First World',\n",
    "    ' Cambodia': 'Third World',\n",
    "    ' England': 'First World',\n",
    "    ' Puerto-Rico': 'Third World',\n",
    "    ' Canada': 'First World',\n",
    "    ' Germany': 'First World',\n",
    "    ' Outlying-US(Guam-USVI-etc)': 'First World',\n",
    "    ' India': 'Third World',\n",
    "    ' Japan': 'First World',\n",
    "    ' Greece': 'First World',\n",
    "    ' South': 'Third World',\n",
    "    ' China': 'Second World',\n",
    "    ' Cuba': 'Second World',\n",
    "    ' Iran': 'Third World',\n",
    "    ' Honduras': 'Third World',\n",
    "    ' Philippines': 'Third World',\n",
    "    ' Italy': 'First World',\n",
    "    ' Poland': 'Second World',\n",
    "    ' Jamaica': 'Third World',\n",
    "    ' Vietnam': 'Second World',\n",
    "    ' Mexico': 'Third World',\n",
    "    ' Portugal': 'First World',\n",
    "    ' Ireland': 'First World',\n",
    "    ' France': 'First World',\n",
    "    ' Dominican-Republic': 'Third World',\n",
    "    ' Laos': 'Third World',\n",
    "    ' Ecuador': 'Third World',\n",
    "    ' Taiwan': 'First World',\n",
    "    ' Haiti': 'Third World',\n",
    "    ' Columbia': 'Third World',\n",
    "    ' Hungary': 'Second World',\n",
    "    ' Guatemala': 'Third World',\n",
    "    ' Nicaragua': 'Third World',\n",
    "    ' Scotland': 'First World',\n",
    "    ' Thailand': 'Third World',\n",
    "    ' Yugoslavia': 'Second World',\n",
    "    ' El-Salvador': 'Third World',\n",
    "    ' Trinadad&Tobago': 'Third World',\n",
    "    ' Peru': 'Third World',\n",
    "    ' Hong': 'First World',\n",
    "    ' Holand-Netherlands': 'First World',\n",
    "    \" ?\": 'Third World'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the native-country column\n",
    "df_copy_2[' native-country'] = df_copy_2[' native-country'].map(native_country_mapping).fillna(df_copy_2[' native-country'])\n",
    "\n",
    "# Apply the mapping to the race column\n",
    "df_copy_2[' race'] = df_copy_2[' race'].map(race_mapping).fillna(df_copy_2[' race'])\n",
    "\n",
    "\n",
    "\n",
    "# Apply the mapping to the relationship column\n",
    "df_copy_2[' relationship'] = df_copy_2[' relationship'].map(relationship_mapping).fillna(df_copy_2[' relationship'])\n",
    "\n",
    "# Apply the mapping to the occupation column\n",
    "df_copy_2[' occupation'] = df_copy_2[' occupation'].map(occupation_mapping).fillna(df_copy_2[' occupation'])\n",
    "\n",
    "# Apply the mapping to the education column\n",
    "df_copy_2[' education'] = df_copy_2[' education'].map(education_mapping).fillna(df_copy_2[' education'])\n",
    "\n",
    "# Apply the mapping to the workclass column\n",
    "df_copy_2[' workclass'] = df_copy_2[' workclass'].map(workclass_mapping).fillna(df_copy_2[' workclass'])\n",
    "\n",
    "df_copy_2[' marital-status'] = df_copy_2[' marital-status'].map(marital_status_mapping).fillna(df_copy_2[' marital-status'])\n",
    "\n",
    "df_copy_2[' native-country'].unique()\n",
    "\n",
    "df_copy_2.columns = df_copy_2.columns.str.strip()\n",
    "df_copy_2\n",
    "\n",
    "df_copy_2['income'] = df_copy_2['income'].map({' >50K': 1, ' <=50K': 0})\n",
    "df_copy_2['relationship'] = df_copy_2['relationship'].map({'Married': 1, 'Unmarried': 0})\n",
    "df_copy_2['marital-status'] = df_copy_2['marital-status'].map({'Married': 1, 'Not Married': 0})\n",
    "df_copy_2['education'] = df_copy_2['education'].map({'Graduate': 1, 'Not Graduate': 0})\n",
    "df_copy_2['race'] = df_copy_2['race'].map({'White': 1, 'Not White': 0})\n",
    "df_copy_2['native-country'] = df_copy_2['native-country'].map({'First World':2,\n",
    "                            'Second World': 1, \n",
    "                            'Third World': 0})\n",
    "df_copy_2['occupation'] = df_copy_2['occupation'].map({'White Collar':2,\n",
    "                            'Blue Collar': 1, \n",
    "                            'Pink Collar': 0})\n",
    "df_copy_2['workclass'] = df_copy_2['workclass'].map({'Private':2,\n",
    "                            'Gov': 1, \n",
    "                            ' Never-worked': 0})\n",
    "df_copy_2['sex'] = df_copy_2['sex'].map({' Male': 1, ' Female': 0})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Separate the 'income' column\n",
    "income = df_copy_2['income']\n",
    "df_copy_2 = df_copy_2.drop(columns=['income'])\n",
    "\n",
    "# Apply StandardScaler to the rest of the DataFrame\n",
    "scaler = StandardScaler()\n",
    "df_copy_2 = pd.DataFrame(scaler.fit_transform(df_copy_2), \n",
    "                         columns=df_copy_2.columns)\n",
    "\n",
    "# Add the 'income' column back\n",
    "df_copy_2['income'] = income\n",
    "df_copy_2\n",
    "\n",
    "df_copy_2 = df_copy_2.drop('relationship', axis=1)\n",
    "df_copy_2\n",
    "\n",
    "\n",
    "# Assuming df_copy_2 is your DataFrame and 'income' is the target column\n",
    "X = df_copy_2.drop('income', axis=1)\n",
    "y = df_copy_2['income']\n",
    "\n",
    "\n",
    "print(\"Original class distribution:\\n\", y.value_counts())\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X,\n",
    "                                              y)\n",
    "\n",
    "print(\"Resampled class distribution:\\n\", y.value_counts())\n",
    "# print(\"Resampled class distribution:\\n\", y_train_res.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                     test_size=0.2,\n",
    "#                                                     random_state=42)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 70% train, 30% temp (which will be split into validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: 50% of temp (15% of original data) for validation and 50% for test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_temp = None\n",
    "y_temp = None\n",
    "\n",
    "# Verifying the sizes\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e284d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:14:16.841160Z",
     "iopub.status.busy": "2024-10-16T18:14:16.840664Z",
     "iopub.status.idle": "2024-10-16T18:17:37.033404Z",
     "shell.execute_reply": "2024-10-16T18:17:37.031581Z"
    },
    "papermill": {
     "duration": 200.212688,
     "end_time": "2024-10-16T18:17:37.036241",
     "exception": false,
     "start_time": "2024-10-16T18:14:16.823553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7639 - loss: 0.4759 - val_accuracy: 0.8201 - val_loss: 0.3844\n",
      "Epoch 2/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8205 - loss: 0.3987 - val_accuracy: 0.8213 - val_loss: 0.3805\n",
      "Epoch 3/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.3899 - val_accuracy: 0.8221 - val_loss: 0.3791\n",
      "Epoch 4/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.3849 - val_accuracy: 0.8266 - val_loss: 0.3772\n",
      "Epoch 5/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.3858 - val_accuracy: 0.8223 - val_loss: 0.3773\n",
      "Epoch 6/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8284 - loss: 0.3822 - val_accuracy: 0.8247 - val_loss: 0.3762\n",
      "Epoch 7/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.3735 - val_accuracy: 0.8265 - val_loss: 0.3759\n",
      "Epoch 8/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.3776 - val_accuracy: 0.8221 - val_loss: 0.3764\n",
      "Epoch 9/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.3778 - val_accuracy: 0.8243 - val_loss: 0.3747\n",
      "Epoch 10/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.3763 - val_accuracy: 0.8255 - val_loss: 0.3745\n",
      "Epoch 11/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.3789 - val_accuracy: 0.8244 - val_loss: 0.3748\n",
      "Epoch 12/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.3752 - val_accuracy: 0.8236 - val_loss: 0.3752\n",
      "Epoch 13/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8272 - loss: 0.3816 - val_accuracy: 0.8243 - val_loss: 0.3730\n",
      "Epoch 14/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8317 - loss: 0.3729 - val_accuracy: 0.8246 - val_loss: 0.3743\n",
      "Epoch 15/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.3767 - val_accuracy: 0.8244 - val_loss: 0.3737\n",
      "Epoch 16/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.3738 - val_accuracy: 0.8252 - val_loss: 0.3723\n",
      "Epoch 17/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.3728 - val_accuracy: 0.8259 - val_loss: 0.3713\n",
      "Epoch 18/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.3722 - val_accuracy: 0.8246 - val_loss: 0.3722\n",
      "Epoch 19/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.3683 - val_accuracy: 0.8265 - val_loss: 0.3713\n",
      "Epoch 20/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8294 - loss: 0.3762 - val_accuracy: 0.8267 - val_loss: 0.3726\n",
      "Epoch 21/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.3758 - val_accuracy: 0.8270 - val_loss: 0.3706\n",
      "Epoch 22/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3745 - val_accuracy: 0.8261 - val_loss: 0.3724\n",
      "Epoch 23/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.3682 - val_accuracy: 0.8262 - val_loss: 0.3702\n",
      "Epoch 24/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8325 - loss: 0.3683 - val_accuracy: 0.8290 - val_loss: 0.3711\n",
      "Epoch 25/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3729 - val_accuracy: 0.8261 - val_loss: 0.3711\n",
      "Epoch 26/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.3665 - val_accuracy: 0.8270 - val_loss: 0.3703\n",
      "Epoch 27/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.3700 - val_accuracy: 0.8279 - val_loss: 0.3693\n",
      "Epoch 28/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3687 - val_accuracy: 0.8275 - val_loss: 0.3693\n",
      "Epoch 29/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.3648 - val_accuracy: 0.8290 - val_loss: 0.3725\n",
      "Epoch 30/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.3714 - val_accuracy: 0.8282 - val_loss: 0.3690\n",
      "Epoch 31/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.3706 - val_accuracy: 0.8282 - val_loss: 0.3699\n",
      "Epoch 32/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.3665 - val_accuracy: 0.8297 - val_loss: 0.3705\n",
      "Epoch 33/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3689 - val_accuracy: 0.8263 - val_loss: 0.3699\n",
      "Epoch 34/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3693 - val_accuracy: 0.8286 - val_loss: 0.3683\n",
      "Epoch 35/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.3650 - val_accuracy: 0.8304 - val_loss: 0.3682\n",
      "Epoch 36/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.3634 - val_accuracy: 0.8275 - val_loss: 0.3685\n",
      "Epoch 37/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.3646 - val_accuracy: 0.8277 - val_loss: 0.3686\n",
      "Epoch 38/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.3676 - val_accuracy: 0.8278 - val_loss: 0.3675\n",
      "Epoch 39/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.3643 - val_accuracy: 0.8279 - val_loss: 0.3684\n",
      "Epoch 40/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.3659 - val_accuracy: 0.8285 - val_loss: 0.3684\n",
      "Epoch 41/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.3711 - val_accuracy: 0.8298 - val_loss: 0.3673\n",
      "Epoch 42/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3607 - val_accuracy: 0.8277 - val_loss: 0.3693\n",
      "Epoch 43/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.3600 - val_accuracy: 0.8278 - val_loss: 0.3677\n",
      "Epoch 44/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.3642 - val_accuracy: 0.8274 - val_loss: 0.3683\n",
      "Epoch 45/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3605 - val_accuracy: 0.8281 - val_loss: 0.3665\n",
      "Epoch 46/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3678 - val_accuracy: 0.8319 - val_loss: 0.3665\n",
      "Epoch 47/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.3663 - val_accuracy: 0.8333 - val_loss: 0.3659\n",
      "Epoch 48/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.3666 - val_accuracy: 0.8301 - val_loss: 0.3669\n",
      "Epoch 49/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.3654 - val_accuracy: 0.8312 - val_loss: 0.3668\n",
      "Epoch 50/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.3622 - val_accuracy: 0.8304 - val_loss: 0.3674\n",
      "Epoch 51/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3607 - val_accuracy: 0.8313 - val_loss: 0.3682\n",
      "Epoch 52/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.3650 - val_accuracy: 0.8298 - val_loss: 0.3678\n",
      "Epoch 53/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3656 - val_accuracy: 0.8310 - val_loss: 0.3660\n",
      "Epoch 54/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.3636 - val_accuracy: 0.8286 - val_loss: 0.3666\n",
      "Epoch 55/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3624 - val_accuracy: 0.8312 - val_loss: 0.3666\n",
      "Epoch 56/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3609 - val_accuracy: 0.8292 - val_loss: 0.3684\n",
      "Epoch 57/100\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8383 - loss: 0.3628 - val_accuracy: 0.8285 - val_loss: 0.3672\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.3653\n",
      "Validation Accuracy: 0.8333\n",
      "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Test Accuracy: 0.8347\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train, X_test, X_val, y_train, y_test, y_val are already defined\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9b291f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:17:37.702022Z",
     "iopub.status.busy": "2024-10-16T18:17:37.701165Z",
     "iopub.status.idle": "2024-10-16T18:17:52.936814Z",
     "shell.execute_reply": "2024-10-16T18:17:52.935340Z"
    },
    "papermill": {
     "duration": 15.574011,
     "end_time": "2024-10-16T18:17:52.939717",
     "exception": false,
     "start_time": "2024-10-16T18:17:37.365706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /opt/conda/lib/python3.10/site-packages (0.44.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from shap) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from shap) (1.14.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from shap) (1.2.2)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from shap) (2.2.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.10/site-packages (from shap) (4.66.4)\r\n",
      "Requirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.10/site-packages (from shap) (21.3)\r\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap) (0.0.7)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from shap) (0.60.0)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from shap) (3.0.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>20.9->shap) (3.1.2)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->shap) (0.43.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2024.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap) (3.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48c71af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:17:53.616512Z",
     "iopub.status.busy": "2024-10-16T18:17:53.615314Z",
     "iopub.status.idle": "2024-10-16T18:18:09.066887Z",
     "shell.execute_reply": "2024-10-16T18:18:09.065088Z"
    },
    "papermill": {
     "duration": 15.80249,
     "end_time": "2024-10-16T18:18:09.069919",
     "exception": false,
     "start_time": "2024-10-16T18:17:53.267429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.14.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7b1ed35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:18:09.724661Z",
     "iopub.status.busy": "2024-10-16T18:18:09.724131Z",
     "iopub.status.idle": "2024-10-16T18:18:09.730142Z",
     "shell.execute_reply": "2024-10-16T18:18:09.728841Z"
    },
    "papermill": {
     "duration": 0.336688,
     "end_time": "2024-10-16T18:18:09.732917",
     "exception": false,
     "start_time": "2024-10-16T18:18:09.396229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from utilityscript2 import *\n",
    "\n",
    "# CommonUtils.get_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9a1677a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:18:10.385839Z",
     "iopub.status.busy": "2024-10-16T18:18:10.385350Z",
     "iopub.status.idle": "2024-10-16T18:18:10.392256Z",
     "shell.execute_reply": "2024-10-16T18:18:10.390809Z"
    },
    "papermill": {
     "duration": 0.336452,
     "end_time": "2024-10-16T18:18:10.395415",
     "exception": false,
     "start_time": "2024-10-16T18:18:10.058963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  # Define the directory path\n",
    "# directory = 'my_dir/best_model'\n",
    "\n",
    "# # Check if the directory exists\n",
    "# if os.path.exists(directory):\n",
    "#     # Remove the directory and its contents\n",
    "#     shutil.rmtree(directory)\n",
    "#     print(f\"Directory '{directory}' has been removed.\")\n",
    "# else:\n",
    "#     print(f\"Directory '{directory}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b1f564f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:18:11.050736Z",
     "iopub.status.busy": "2024-10-16T18:18:11.050270Z",
     "iopub.status.idle": "2024-10-16T18:18:11.058094Z",
     "shell.execute_reply": "2024-10-16T18:18:11.057011Z"
    },
    "papermill": {
     "duration": 0.339804,
     "end_time": "2024-10-16T18:18:11.060839",
     "exception": false,
     "start_time": "2024-10-16T18:18:10.721035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras_tuner import RandomSearch\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# # # def build_model(hp):\n",
    "# # #     model = Sequential()\n",
    "# # #     model.add(Dense(hp.Int('units', min_value=32, max_value=1020, \n",
    "# # #                            step=32), activation='relu',\n",
    "# # #                     input_dim=X_train.shape[1]))\n",
    "# # #     for i in range(hp.Int('num_layers', 1, 3)):\n",
    "# # #         model.add(Dense(hp.Int(f'units_{i}', min_value=32,\n",
    "# # #                                max_value=512, step=32), activation='relu'))\n",
    "# # #     model.add(Dense(1, activation='sigmoid'))\n",
    "# # #     model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "# # #                   metrics=['accuracy'])\n",
    "# # #     return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = Sequential()\n",
    "#     model.add(tf.keras.layers.Input(shape=(X_train.shape[1],)))\n",
    "#     model.add(Dense(hp.Int('units', min_value=32, max_value=1020,\n",
    "#                            step=32), activation='relu'))\n",
    "#     for i in range(hp.Int('num_layers', 1, 6)):\n",
    "#         model.add(Dense(hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
    "#                         activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # tuner = RandomSearch(\n",
    "# #     build_model,\n",
    "# #     objective='val_accuracy',\n",
    "# #     max_trials=20,   \n",
    "# #     executions_per_trial=  10, # 6, # 1,\n",
    "# #     directory='my_dir',\n",
    "# #     project_name='best_model'\n",
    "# # )\n",
    "\n",
    "# from keras_tuner import BayesianOptimization\n",
    "\n",
    "\n",
    "# tuner = BayesianOptimization(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_trials=20,   \n",
    "#     executions_per_trial=1,  \n",
    "#     directory='my_dir',\n",
    "#     project_name='best_model'\n",
    "# )\n",
    "\n",
    "\n",
    "# tuner.search(X_train, y_train, epochs=10000, validation_data=(X_val,\n",
    "#                                                                     y_val),\n",
    "#              callbacks=CommonUtils.get_callbacks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "352cb477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:18:11.779222Z",
     "iopub.status.busy": "2024-10-16T18:18:11.778108Z",
     "iopub.status.idle": "2024-10-16T18:18:26.520227Z",
     "shell.execute_reply": "2024-10-16T18:18:26.518247Z"
    },
    "papermill": {
     "duration": 15.13286,
     "end_time": "2024-10-16T18:18:26.523601",
     "exception": false,
     "start_time": "2024-10-16T18:18:11.390741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_tuner in /opt/conda/lib/python3.10/site-packages (1.4.7)\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (3.3.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (21.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (2.32.3)\r\n",
      "Requirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (1.0.5)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (1.26.4)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (3.11.0)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.3.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras_tuner) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (2024.8.30)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras->keras_tuner) (4.12.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras_tuner) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras_tuner) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4b54ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:18:27.177167Z",
     "iopub.status.busy": "2024-10-16T18:18:27.176637Z",
     "iopub.status.idle": "2024-10-16T18:18:27.183794Z",
     "shell.execute_reply": "2024-10-16T18:18:27.182376Z"
    },
    "papermill": {
     "duration": 0.33798,
     "end_time": "2024-10-16T18:18:27.186606",
     "exception": false,
     "start_time": "2024-10-16T18:18:26.848626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras_tuner import RandomSearch\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "#  # Define the directory path\n",
    "# directory = 'my_dir/best_model'\n",
    "\n",
    "# # Check if the directory exists\n",
    "# if os.path.exists(directory):\n",
    "#     # Remove the directory and its contents\n",
    "#     shutil.rmtree(directory)\n",
    "#     print(f\"Directory '{directory}' has been removed.\")\n",
    "# else:\n",
    "#     print(f\"Directory '{directory}' does not exist.\")\n",
    "\n",
    "# # Detect and initialize the TPU\n",
    "# try:\n",
    "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n",
    "#     tf.config.experimental_connect_to_cluster(tpu)\n",
    "#     tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "#     strategy = tf.distribute.TPUStrategy(tpu)  # Create a strategy for TPU\n",
    "#     print(\"TPU detected and initialized\")\n",
    "# except ValueError:\n",
    "#     strategy = tf.distribute.get_strategy()  # Default strategy for CPU and GPU\n",
    "#     print(\"TPU not detected, using default strategy\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70bd2cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:18:27.852192Z",
     "iopub.status.busy": "2024-10-16T18:18:27.851549Z",
     "iopub.status.idle": "2024-10-16T18:18:43.782987Z",
     "shell.execute_reply": "2024-10-16T18:18:43.781026Z"
    },
    "papermill": {
     "duration": 16.264162,
     "end_time": "2024-10-16T18:18:43.786573",
     "exception": false,
     "start_time": "2024-10-16T18:18:27.522411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_tuner in /opt/conda/lib/python3.10/site-packages (1.4.7)\r\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (3.3.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (21.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (2.32.3)\r\n",
      "Requirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras_tuner) (1.0.5)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (1.26.4)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.0.8)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (3.11.0)\r\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.11.0)\r\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras->keras_tuner) (0.3.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras_tuner) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->keras_tuner) (2024.8.30)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras->keras_tuner) (4.12.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras_tuner) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras_tuner) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2599816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:18:44.475077Z",
     "iopub.status.busy": "2024-10-16T18:18:44.472898Z",
     "iopub.status.idle": "2024-10-16T18:18:44.484432Z",
     "shell.execute_reply": "2024-10-16T18:18:44.482261Z"
    },
    "papermill": {
     "duration": 0.359136,
     "end_time": "2024-10-16T18:18:44.487565",
     "exception": false,
     "start_time": "2024-10-16T18:18:44.128429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras_tuner import BayesianOptimization\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# # Check for TPU availability and set up the TPU strategy\n",
    "# try:\n",
    "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n",
    "#     tf.config.experimental_connect_to_cluster(tpu)\n",
    "#     tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "#     strategy = tf.distribute.TPUStrategy(tpu)\n",
    "#     print(\"Running on TPU:\", tpu.master())\n",
    "# except ValueError:\n",
    "#     strategy = tf.distribute.get_strategy()  # Use the default strategy if TPU is unavailable\n",
    "#     print(\"Running on default strategy (CPU/GPU)\")\n",
    "\n",
    "# # Define the model within the TPU strategy scope\n",
    "# def build_model(hp):\n",
    "#     with strategy.scope():\n",
    "#         model = Sequential()\n",
    "#         model.add(tf.keras.layers.Input(shape=(X_train.shape[1],)))\n",
    "#         model.add(Dense(hp.Int('units', min_value=32, max_value=1020, step=32), activation='relu'))\n",
    "#         for i in range(hp.Int('num_layers', 1, 6)):\n",
    "#             model.add(Dense(hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
    "#                             activation='relu'))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "#         model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Initialize the tuner inside the TPU strategy scope\n",
    "# with strategy.scope():\n",
    "#     tuner = BayesianOptimization(\n",
    "#         build_model,\n",
    "#         objective='val_accuracy',\n",
    "#         max_trials=20,   \n",
    "#         executions_per_trial=10,  \n",
    "#         directory='my_dir',\n",
    "#         project_name='best_model'\n",
    "#     )\n",
    "\n",
    "# # Train the model with the tuner inside the strategy scope\n",
    "# with strategy.scope():\n",
    "#     tuner.search(X_train, y_train, epochs=10000, validation_data=(X_val, y_val),\n",
    "#                  callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06eb233e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T18:18:45.240558Z",
     "iopub.status.busy": "2024-10-16T18:18:45.240096Z",
     "iopub.status.idle": "2024-10-16T18:18:45.245911Z",
     "shell.execute_reply": "2024-10-16T18:18:45.244507Z"
    },
    "papermill": {
     "duration": 0.417842,
     "end_time": "2024-10-16T18:18:45.249177",
     "exception": false,
     "start_time": "2024-10-16T18:18:44.831335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_model = tuner.get_best_models(num_models=1)[0]\n",
    "# best_model.evaluate(X_test_new, y_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c398aa",
   "metadata": {
    "papermill": {
     "duration": 0.3439,
     "end_time": "2024-10-16T18:18:45.936283",
     "exception": false,
     "start_time": "2024-10-16T18:18:45.592383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 149550,
     "sourceId": 346098,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 199076115,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 925.3236,
   "end_time": "2024-10-16T18:18:48.901112",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-16T18:03:23.577512",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
