{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c863f56-09bd-4c70-8b6d-ac952d35042c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-23 22:07:07.987116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-23 22:07:25.992837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from matplotlib import pyplot\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "def get_metadata(file_name):\n",
    "    if file_name[-len('03-01-06-02-02-01-07.wav'):][6:8] == '01':\n",
    "        emo = 'neutral'\n",
    "    elif file_name[-len('03-01-06-02-02-01-07.wav'):][6:8] == '02':\n",
    "        emo = 'calm'\n",
    "    elif file_name[-len('03-01-06-02-02-01-07.wav'):][6:8] == '03':\n",
    "        emo = 'happy'\n",
    "    elif file_name[-len('03-01-06-02-02-01-07.wav'):][6:8] == '04':\n",
    "        emo = 'sad'\n",
    "    elif file_name[-len('03-01-06-02-02-01-07.wav'):][6:8] == '05':\n",
    "        emo = 'angry'\n",
    "    elif file_name[-len('03-01-06-02-02-01-07.wav'):][6:8] == '06':\n",
    "        emo = 'fearful'\n",
    "    elif file_name[-len('03-01-06-02-02-01-07.wav'):][6:8] == '07':\n",
    "        emo = 'disgust'\n",
    "    elif file_name[-len('03-01-06-02-02-01-07.wav'):][6:8] == '08':\n",
    "        emo = 'surprised'\n",
    "        \n",
    "    if int(file_name[-len('03-01-06-02-02-01-07.wav'):][18:20]) % 2 == 0:  # Gender\n",
    "        gen = 'female'\n",
    "    else:\n",
    "        gen = 'male'\n",
    "        # 01 = neutral, 02 = calm, 03 = happy, 04 = sad, \n",
    "        # 05 = angry, 06 = fearful, 07 = disgust, \n",
    "        # 08 = surprised\n",
    "    return emo, gen\n",
    "\n",
    "\n",
    "fn = []\n",
    "for dirname, _, filenames in os.walk('/mount/Project/Project Files/Data/Audio/Audio Speech Sentiment/'):\n",
    "    for filename in filenames:\n",
    "        fn.append(os.path.join(dirname, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58de666-cae5-4d84-868c-a43f2408f4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afed3be-8371-4f87-bfab-85e3aa5e0b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import wave\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba63c74e-40a8-474e-a74b-1fc3bdbbcf55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature(file):\n",
    "    audio, sample_rate = librosa.load(file, \n",
    "                                      # res_type='kaiser_fast'\n",
    "                                     ) \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154f3964-ceaf-4aae-81cd-6b274044759b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract MFCC features\n",
    "mfcc_features = get_feature(fn[0])\n",
    "\n",
    "len(mfcc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c352ed42-2e4d-48fd-aca5-a4e8185472b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mfcc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dab50a4-406b-4060-b028-a0c94d5884d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90795745-4915-4c07-8947-a2f4f2ff5790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "800e68ad-4ca0-4df2-8d1f-eb52044f549a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c4f68-7827-4e00-bd9f-42c4fcb833f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb106cba-f55f-4ebd-9e97-3655c5bdbe63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ef3d6-996e-40ba-8110-12f06bf4b736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b04074-fa77-4622-9b85-55364735722e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████| 1440/1440 [01:48<00:00, 13.29file/s]\n",
      "2023-07-24 14:06:09.004135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-24 14:06:09.157800: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize empty lists\n",
    "male_features = []\n",
    "male_labels = []\n",
    "# female_features = []\n",
    "# female_labels = []\n",
    "\n",
    "# Use tqdm to track progress\n",
    "for curr_file in tqdm(fn, desc=\"Processing files\", \n",
    "                      unit=\"file\"):\n",
    "    curr_feat = get_feature(curr_file)\n",
    "    curr_meta = get_metadata(curr_file)\n",
    "    if curr_meta[1] == 'male':\n",
    "        male_features.append(curr_feat)\n",
    "        male_labels.append(curr_meta[0])\n",
    "    # else:\n",
    "    #     # female_features.append(curr_feat)\n",
    "    #     # female_labels.append(curr_meta[0])\n",
    "    #     continue\n",
    "    \n",
    "# Define the list of possible values\n",
    "possible_values = list(set(male_labels))\n",
    "\n",
    "# Your list of strings to be encoded\n",
    "# input_strings = ['happy', 'sad', 'angry', 'calm']\n",
    "\n",
    "# Create a mapping from each value to its index\n",
    "value_to_index = {value: index for index, value in enumerate(possible_values)}\n",
    "\n",
    "# Map each string to its corresponding index\n",
    "encoded_indices = [value_to_index[string] for string in male_labels]\n",
    "\n",
    "# Perform one-hot encoding\n",
    "one_hot_matrix = tf.one_hot(indices=encoded_indices, depth=len(possible_values))\n",
    "\n",
    "# Convert the TensorFlow tensor to a NumPy array (optional)\n",
    "male_labels_en = one_hot_matrix.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5d2955-f5b2-4708-b0d5-dd4d92908a25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "male_features = np.array(male_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18487ef3-5eed-487a-b8ee-69e39c5a8164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "male_features_train, male_features_test, male_labels_train_en, male_labels_test_en = train_test_split(\n",
    "    male_features, male_labels_en, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67269e01-fba0-4c0f-900e-98283733eca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded vectors\n",
    "num_classes = len(male_labels_test_en[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf588dd7-bb8f-4606-b5d7-3657c6ae52fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab6590-a9f8-4875-b972-7bffdbe4a4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20d254d-cc52-4d7f-961e-cb590e86e7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8611806-e1df-4881-91de-77f1b201d57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = male_features_train\n",
    "X_test = male_features_test\n",
    "y_train = male_labels_train_en\n",
    "y_test = male_labels_test_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0205c702-f20d-4f31-9c0d-37f21d1110a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape the features for CNN input (assuming each MFCC feature# Reshape the features for CNN input (assuming each MFCC feature is a row)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "512ef12d-019f-4d60-a041-c7c1d0b1740a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv2d_4/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_4/Conv2D/ReadVariableOp)' with input shapes: [?,40,1,1], [2,2,1,32].\n\nCall arguments received by layer \"conv2d_4\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 40, 1, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Build the CNN model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.25\u001b[39m))\n",
      "File \u001b[0;32m/mount/Project/Project Files/PythonEnvs/DataSciEnv2/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/mount/Project/Project Files/PythonEnvs/DataSciEnv2/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mount/Project/Project Files/PythonEnvs/DataSciEnv2/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1973\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1970\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1972\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1973\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node conv2d_4/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_4/Conv2D/ReadVariableOp)' with input shapes: [?,40,1,1], [2,2,1,32].\n\nCall arguments received by layer \"conv2d_4\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 40, 1, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(X_train.shape[1], 1, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9e249-b016-4a96-832a-8bca6c7d711e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
